---
title: API æ‰‹å†Œ
description: è€å¼ API æ¥å£ä½¿ç”¨æ‰‹å†Œå’Œå‚è€ƒæ–‡æ¡£ï¼Œæœ¬æ‰‹å†Œæä¾› è€å¼ API çš„å®Œæ•´æ¥å£æ–‡æ¡£ï¼Œå¸®åŠ©æ‚¨å¿«é€Ÿé›†æˆå’Œä½¿ç”¨æˆ‘ä»¬çš„æœåŠ¡ã€‚

icon: "book"
---

## å¹³å°ç‰¹è‰²

### OpenAI å…¼å®¹æ¨¡å¼

è€å¼ APIé‡‡ç”¨ **OpenAI å…¼å®¹æ ¼å¼**ï¼Œè®©æ‚¨å¯ä»¥ç”¨ç»Ÿä¸€çš„æ¥å£è°ƒç”¨200+ä¸»æµå¤§æ¨¡å‹ï¼š

**æ”¯æŒçš„æ¨¡å‹å‚å•†ï¼š**
- ğŸ¤– **OpenAI**ï¼šgpt-4oã€gpt-5-chat-latestã€gpt-3.5-turboç­‰
- ğŸ§  **Anthropic**ï¼šclaude-sonnet-4-20250514ã€claude-opus-4-1-20250805 ç­‰  
- ğŸ’ **Google**ï¼šgemini-2.5-proã€gemini-2.5-flash ç­‰
- ğŸš€ **xAI**ï¼šgrok-4-0709ã€grok-3 ç­‰
- ğŸ” **DeepSeek**ï¼šdeepSeek-r1ã€deepSeek-v3 ç­‰
- ğŸŒŸ **é˜¿é‡Œ**ï¼šQwenç³»åˆ—æ¨¡å‹
- ğŸ’¬ **Moonshot**ï¼šKimiæ¨¡å‹ç­‰

### åŠŸèƒ½æ”¯æŒèŒƒå›´

**âœ… æ”¯æŒçš„åŠŸèƒ½ï¼š**
- ğŸ’¬ **å¯¹è¯è¡¥å…¨**ï¼šChat Completionsæ¥å£
- ğŸ–¼ï¸ **å›¾åƒç”Ÿæˆ**ï¼šgpt-image-1ã€flux-kontext-proã€flux-kontext-max ç­‰
- ğŸ”Š **è¯­éŸ³å¤„ç†**ï¼šWhisperè½¬å½•
- ğŸ“Š **åµŒå…¥å‘é‡**ï¼šæ–‡æœ¬å‘é‡åŒ–
- âš¡ **å‡½æ•°è°ƒç”¨**ï¼šFunction Calling
- ğŸ“¡ **æµå¼è¾“å‡º**ï¼šå®æ—¶å“åº”
- ğŸ”§ **OpenAIå‚æ•°**ï¼štemperatureã€top_pã€max_tokensç­‰
- ğŸ†• **Responsesç«¯ç‚¹**ï¼šOpenAIæœ€æ–°åŠŸèƒ½

**âŒ ä¸æ”¯æŒçš„åŠŸèƒ½ï¼š**
- ğŸ”§ å¾®è°ƒæ¥å£ï¼ˆFine-tuningï¼‰
- ğŸ“ Filesç®¡ç†æ¥å£
- ğŸ¢ ç»„ç»‡ç®¡ç†æ¥å£
- ğŸ’³ è®¡è´¹ç®¡ç†æ¥å£

### ç®€å•åˆ‡æ¢æ¨¡å‹

**æ ¸å¿ƒä¼˜åŠ¿ï¼šä¸€å¥—ä»£ç ï¼Œå¤šç§æ¨¡å‹**

ç”¨OpenAIæ ¼å¼è·‘é€šåï¼Œåªéœ€è¦**æ›´æ¢æ¨¡å‹åç§°**å³å¯åˆ‡æ¢åˆ°å…¶ä»–å¤§æ¨¡å‹ï¼š

```python
# ä½¿ç”¨GPT-4o
response = client.chat.completions.create(
    model="gpt-4o",  # OpenAIæ¨¡å‹
    messages=[...]
)

# åˆ‡æ¢åˆ°Claudeï¼Œå…¶ä»–ä»£ç å®Œå…¨ä¸å˜ï¼
response = client.chat.completions.create(
    model="claude-3.5-sonnet",  # åªæ”¹æ¨¡å‹å
    messages=[...]
)

# åˆ‡æ¢åˆ°Gemini
response = client.chat.completions.create(
    model="gemini-1.5-pro",  # åªæ”¹æ¨¡å‹å
    messages=[...]
)
```

<Tip>
è¿™ç§è®¾è®¡è®©æ‚¨å¯ä»¥è½»æ¾å¯¹æ¯”ä¸åŒæ¨¡å‹çš„æ•ˆæœï¼Œæˆ–æ ¹æ®æˆæœ¬å’Œæ€§èƒ½éœ€æ±‚çµæ´»åˆ‡æ¢æ¨¡å‹ï¼Œæ— éœ€é‡å†™ä»£ç ï¼
</Tip>

## å¿«é€Ÿå¼€å§‹

### è·å–API Key

1. è®¿é—® [è€å¼ APIæ§åˆ¶å°](https://api.laozhang.ai/token)
2. ç™»å½•æ‚¨çš„è´¦æˆ·
3. åœ¨ä»¤ç‰Œç®¡ç†é¡µé¢ç‚¹å‡»"æ–°å¢"åˆ›å»ºAPI Key
4. å¤åˆ¶ç”Ÿæˆçš„API Keyç”¨äºæ¥å£è°ƒç”¨

### æŸ¥çœ‹è¯·æ±‚ç¤ºä¾‹

åœ¨ä»¤ç‰Œç®¡ç†é¡µé¢ï¼Œæ‚¨å¯ä»¥å¿«é€Ÿè·å–å„ç§ç¼–ç¨‹è¯­è¨€çš„ä»£ç ç¤ºä¾‹ï¼š

**æ“ä½œæ­¥éª¤ï¼š**
1. è¿›å…¥ [ä»¤ç‰Œç®¡ç†é¡µé¢](https://api.laozhang.ai/token)
2. æ‰¾åˆ°æ‚¨è¦ä½¿ç”¨çš„API Keyæ‰€åœ¨çš„è¡Œ
3. ç‚¹å‡»"æ“ä½œ"åˆ—ä¸­çš„ğŸ”§**å°æ‰³æ‰‹å›¾æ ‡**ï¼ˆå·¥å…·å›¾æ ‡ï¼‰
4. åœ¨å¼¹å‡ºèœå•ä¸­é€‰æ‹©"**è¯·æ±‚ç¤ºä¾‹**"
5. æŸ¥çœ‹åŒ…å«ä»¥ä¸‹è¯­è¨€çš„å®Œæ•´ä»£ç ç¤ºä¾‹ï¼š

<img src="/images/apiyi-token-simple-code.png" alt="è€å¼ APIä»¤ç‰Œç®¡ç†ç•Œé¢" />


**æ”¯æŒçš„ç¼–ç¨‹è¯­è¨€ï¼š**
- **cURL** - å‘½ä»¤è¡Œæµ‹è¯•
- **Python (SDK)** - ä½¿ç”¨å®˜æ–¹OpenAIåº“
- **Python (requests)** - ä½¿ç”¨requestsåº“
- **Node.js** - JavaScript/TypeScript
- **Java** - Javaåº”ç”¨å¼€å‘
- **C#** - .NETåº”ç”¨å¼€å‘
- **Go** - Goè¯­è¨€å¼€å‘
- **PHP** - Webå¼€å‘
- **Ruby** - Rubyåº”ç”¨å¼€å‘
- ä»¥åŠæ›´å¤šè¯­è¨€...

**ä»£ç ç¤ºä¾‹ç‰¹ç‚¹ï¼š**
- âœ… **å®Œæ•´å¯è¿è¡Œ**ï¼šå¤åˆ¶ç²˜è´´å³å¯ä½¿ç”¨
- âœ… **å‚æ•°è¯´æ˜**ï¼šè¯¦ç»†çš„å‚æ•°é…ç½®
- âœ… **é”™è¯¯å¤„ç†**ï¼šåŒ…å«å¼‚å¸¸å¤„ç†é€»è¾‘
- âœ… **æœ€ä½³å®è·µ**ï¼šéµå¾ªå„è¯­è¨€å¼€å‘è§„èŒƒ

<Note>
å»ºè®®å¼€å‘è€…ä¼˜å…ˆæŸ¥çœ‹åå°çš„è¯·æ±‚ç¤ºä¾‹ï¼Œè¿™äº›ç¤ºä¾‹ä¼šæ ¹æ®æœ€æ–°çš„APIç‰ˆæœ¬å®æ—¶æ›´æ–°ï¼Œç¡®ä¿ä»£ç çš„å‡†ç¡®æ€§å’Œå¯ç”¨æ€§ã€‚
</Note>

## åŸºç¡€ä¿¡æ¯

### API ç«¯ç‚¹

- **ä¸»è¦ç«¯ç‚¹**ï¼š`https://api.laozhang.ai/v1`
- **å¤‡ç”¨ç«¯ç‚¹**ï¼š`https://api-cf.laozhang.ai/v1`

### è®¤è¯æ–¹å¼

æ‰€æœ‰ API è¯·æ±‚éœ€è¦åœ¨ Header ä¸­åŒ…å«è®¤è¯ä¿¡æ¯ï¼š

```http
Authorization: Bearer YOUR_API_KEY
```

### è¯·æ±‚æ ¼å¼

- **Content-Type**ï¼š`application/json`
- **ç¼–ç æ ¼å¼**ï¼šUTF-8
- **è¯·æ±‚æ–¹æ³•**ï¼šPOSTï¼ˆå¤§éƒ¨åˆ†æ¥å£ï¼‰

## æ ¸å¿ƒæ¥å£

### 1. å¯¹è¯è¡¥å…¨ï¼ˆChat Completionsï¼‰

åˆ›å»ºä¸€ä¸ªå¯¹è¯è¡¥å…¨è¯·æ±‚ï¼Œæ”¯æŒå¤šè½®å¯¹è¯ã€‚

**è¯·æ±‚ç«¯ç‚¹**
```
POST /v1/chat/completions
```

**è¯·æ±‚å‚æ•°**

| å‚æ•° | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|------|------|------|------|
| model | string | æ˜¯ | æ¨¡å‹åç§°ï¼Œå¦‚ `gpt-3.5-turbo` |
| messages | array | æ˜¯ | å¯¹è¯æ¶ˆæ¯æ•°ç»„ |
| temperature | number | å¦ | é‡‡æ ·æ¸©åº¦ï¼Œ0-2ä¹‹é—´ï¼Œé»˜è®¤1 |
| max_tokens | integer | å¦ | æœ€å¤§ç”Ÿæˆä»¤ç‰Œæ•° |
| stream | boolean | å¦ | æ˜¯å¦æµå¼è¿”å›ï¼Œé»˜è®¤false |
| top_p | number | å¦ | æ ¸é‡‡æ ·å‚æ•°ï¼Œ0-1ä¹‹é—´ |
| n | integer | å¦ | ç”Ÿæˆæ•°é‡ï¼Œé»˜è®¤1 |
| stop | string/array | å¦ | åœæ­¢åºåˆ— |
| presence_penalty | number | å¦ | å­˜åœ¨æƒ©ç½šï¼Œ-2åˆ°2ä¹‹é—´ |
| frequency_penalty | number | å¦ | é¢‘ç‡æƒ©ç½šï¼Œ-2åˆ°2ä¹‹é—´ |

**æ¶ˆæ¯æ ¼å¼**
```json
{
  "role": "system|user|assistant",
  "content": "æ¶ˆæ¯å†…å®¹"
}
```

**å®Œæ•´ä»£ç ç¤ºä¾‹**

<Tabs>
  <Tab title="cURL">
    ```bash
    curl -X POST "https://api.laozhang.ai/v1/chat/completions" \
      -H "Authorization: Bearer YOUR_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "gpt-3.5-turbo",
        "messages": [
          {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"},
          {"role": "user", "content": "ä½ å¥½ï¼è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚"}
        ],
        "temperature": 0.7,
        "max_tokens": 1000
      }'
    ```
  </Tab>
  
  <Tab title="Python (SDK)">
    ```python
    from openai import OpenAI
    
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = OpenAI(
        api_key="YOUR_API_KEY",
        base_url="https://api.laozhang.ai/v1"
    )
    
    # å‘é€èŠå¤©è¯·æ±‚
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"},
            {"role": "user", "content": "ä½ å¥½ï¼è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚"}
        ],
        temperature=0.7,
        max_tokens=1000
    )
    
    print(response.choices[0].message.content)
    ```
  </Tab>
  
  <Tab title="Python (requests)">
    ```python
    import requests
    import json
    
    url = "https://api.laozhang.ai/v1/chat/completions"
    headers = {
        "Authorization": "Bearer YOUR_API_KEY",
        "Content-Type": "application/json"
    }
    
    data = {
        "model": "gpt-3.5-turbo",
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"},
            {"role": "user", "content": "ä½ å¥½ï¼è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚"}
        ],
        "temperature": 0.7,
        "max_tokens": 1000
    }
    
    response = requests.post(url, headers=headers, json=data)
    result = response.json()
    
    if response.status_code == 200:
        print(result["choices"][0]["message"]["content"])
    else:
        print(f"é”™è¯¯: {result}")
    ```
  </Tab>
  
  <Tab title="Node.js">
    ```javascript
    const OpenAI = require('openai');
    
    const client = new OpenAI({
      apiKey: 'YOUR_API_KEY',
      baseURL: 'https://api.laozhang.ai/v1'
    });
    
    async function chatCompletion() {
      try {
        const response = await client.chat.completions.create({
          model: 'gpt-3.5-turbo',
          messages: [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"},
            {"role": "user", "content": "ä½ å¥½ï¼è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚"}
          ],
          temperature: 0.7,
          max_tokens: 1000
        });
        
        console.log(response.choices[0].message.content);
      } catch (error) {
        console.error('APIè°ƒç”¨é”™è¯¯:', error);
      }
    }
    
    chatCompletion();
    ```
  </Tab>
  
  <Tab title="Java">
    ```java
    import okhttp3.*;
    import com.google.gson.Gson;
    import java.io.IOException;
    import java.util.*;
    
    public class LaoZhangExample {
        private static final String API_KEY = "YOUR_API_KEY";
        private static final String BASE_URL = "https://api.laozhang.ai/v1";
        
        public static void main(String[] args) throws IOException {
            OkHttpClient client = new OkHttpClient();
            Gson gson = new Gson();
            
            // æ„å»ºè¯·æ±‚ä½“
            Map<String, Object> requestBody = new HashMap<>();
            requestBody.put("model", "gpt-3.5-turbo");
            requestBody.put("temperature", 0.7);
            requestBody.put("max_tokens", 1000);
            
            List<Map<String, String>> messages = Arrays.asList(
                Map.of("role", "system", "content", "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"),
                Map.of("role", "user", "content", "ä½ å¥½ï¼è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚")
            );
            requestBody.put("messages", messages);
            
            RequestBody body = RequestBody.create(
                gson.toJson(requestBody),
                MediaType.parse("application/json")
            );
            
            Request request = new Request.Builder()
                .url(BASE_URL + "/chat/completions")
                .addHeader("Authorization", "Bearer " + API_KEY)
                .addHeader("Content-Type", "application/json")
                .post(body)
                .build();
            
            try (Response response = client.newCall(request).execute()) {
                System.out.println(response.body().string());
            }
        }
    }
    ```
  </Tab>
  
  <Tab title="C#">
    ```csharp
    using System;
    using System.Net.Http;
    using System.Text;
    using System.Threading.Tasks;
    using Newtonsoft.Json;
    
    class Program
    {
        private static readonly string API_KEY = "YOUR_API_KEY";
        private static readonly string BASE_URL = "https://api.laozhang.ai/v1";
        
        static async Task Main(string[] args)
        {
            using var client = new HttpClient();
            client.DefaultRequestHeaders.Add("Authorization", $"Bearer {API_KEY}");
            
            var requestBody = new
            {
                model = "gpt-3.5-turbo",
                messages = new[]
                {
                    new { role = "system", content = "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚" },
                    new { role = "user", content = "ä½ å¥½ï¼è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚" }
                },
                temperature = 0.7,
                max_tokens = 1000
            };
            
            var json = JsonConvert.SerializeObject(requestBody);
            var content = new StringContent(json, Encoding.UTF8, "application/json");
            
            try
            {
                var response = await client.PostAsync($"{BASE_URL}/chat/completions", content);
                var result = await response.Content.ReadAsStringAsync();
                Console.WriteLine(result);
            }
            catch (Exception ex)
            {
                Console.WriteLine($"é”™è¯¯: {ex.Message}");
            }
        }
    }
    ```
  </Tab>
  
  <Tab title="Go">
    ```go
    package main
    
    import (
        "bytes"
        "encoding/json"
        "fmt"
        "io/ioutil"
        "net/http"
    )
    
    type Message struct {
        Role    string `json:"role"`
        Content string `json:"content"`
    }
    
    type ChatRequest struct {
        Model       string    `json:"model"`
        Messages    []Message `json:"messages"`
        Temperature float64   `json:"temperature"`
        MaxTokens   int       `json:"max_tokens"`
    }
    
    func main() {
        apiKey := "YOUR_API_KEY"
        baseURL := "https://api.laozhang.ai/v1"
        
        reqData := ChatRequest{
            Model: "gpt-3.5-turbo",
            Messages: []Message{
                {Role: "system", Content: "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"},
                {Role: "user", Content: "ä½ å¥½ï¼è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚"},
            },
            Temperature: 0.7,
            MaxTokens:   1000,
        }
        
        jsonData, _ := json.Marshal(reqData)
        
        req, _ := http.NewRequest("POST", baseURL+"/chat/completions", bytes.NewBuffer(jsonData))
        req.Header.Set("Authorization", "Bearer "+apiKey)
        req.Header.Set("Content-Type", "application/json")
        
        client := &http.Client{}
        resp, err := client.Do(req)
        if err != nil {
            fmt.Printf("è¯·æ±‚é”™è¯¯: %v\n", err)
            return
        }
        defer resp.Body.Close()
        
        body, _ := ioutil.ReadAll(resp.Body)
        fmt.Println(string(body))
    }
    ```
  </Tab>
  
  <Tab title="PHP">
    ```php
    <?php
    $api_key = 'YOUR_API_KEY';
    $base_url = 'https://api.laozhang.ai/v1';
    
    $data = array(
        'model' => 'gpt-3.5-turbo',
        'messages' => array(
            array('role' => 'system', 'content' => 'ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚'),
            array('role' => 'user', 'content' => 'ä½ å¥½ï¼è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚')
        ),
        'temperature' => 0.7,
        'max_tokens' => 1000
    );
    
    $ch = curl_init();
    curl_setopt($ch, CURLOPT_URL, $base_url . '/chat/completions');
    curl_setopt($ch, CURLOPT_POST, 1);
    curl_setopt($ch, CURLOPT_POSTFIELDS, json_encode($data));
    curl_setopt($ch, CURLOPT_HTTPHEADER, array(
        'Authorization: Bearer ' . $api_key,
        'Content-Type: application/json'
    ));
    curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);
    
    $response = curl_exec($ch);
    $http_code = curl_getinfo($ch, CURLINFO_HTTP_CODE);
    curl_close($ch);
    
    if ($http_code == 200) {
        $result = json_decode($response, true);
        echo $result['choices'][0]['message']['content'];
    } else {
        echo "é”™è¯¯: " . $response;
    }
    ?>
    ```
  </Tab>
  
  <Tab title="Ruby">
    ```ruby
    require 'net/http'
    require 'json'
    
    api_key = 'YOUR_API_KEY'
    base_url = 'https://api.laozhang.ai/v1'
    
    uri = URI("#{base_url}/chat/completions")
    http = Net::HTTP.new(uri.host, uri.port)
    http.use_ssl = true
    
    request = Net::HTTP::Post.new(uri)
    request['Authorization'] = "Bearer #{api_key}"
    request['Content-Type'] = 'application/json'
    
    request.body = {
      model: 'gpt-3.5-turbo',
      messages: [
        { role: 'system', content: 'ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚' },
        { role: 'user', content: 'ä½ å¥½ï¼è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±ã€‚' }
      ],
      temperature: 0.7,
      max_tokens: 1000
    }.to_json
    
    response = http.request(request)
    
    if response.code == '200'
      result = JSON.parse(response.body)
      puts result['choices'][0]['message']['content']
    else
      puts "é”™è¯¯: #{response.body}"
    end
    ```
  </Tab>
</Tabs>

**å“åº”ç¤ºä¾‹**
```json
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "created": 1699000000,
  "model": "gpt-3.5-turbo",
  "choices": [{
    "index": 0,
    "message": {
      "role": "assistant",
      "content": "Hello! How can I help you today?"
    },
    "finish_reason": "stop"
  }],
  "usage": {
    "prompt_tokens": 20,
    "completion_tokens": 10,
    "total_tokens": 30
  }
}
```

### 2. æ–‡æœ¬è¡¥å…¨ï¼ˆCompletionsï¼‰

ä¸ºå…¼å®¹æ—§ç‰ˆæ¥å£ä¿ç•™ï¼Œå»ºè®®ä½¿ç”¨ Chat Completionsã€‚

**è¯·æ±‚ç«¯ç‚¹**
```
POST /v1/completions
```

**è¯·æ±‚å‚æ•°**

| å‚æ•° | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|------|------|------|------|
| model | string | æ˜¯ | æ¨¡å‹åç§° |
| prompt | string/array | æ˜¯ | æç¤ºæ–‡æœ¬ |
| max_tokens | integer | å¦ | æœ€å¤§ç”Ÿæˆé•¿åº¦ |
| temperature | number | å¦ | é‡‡æ ·æ¸©åº¦ |
| top_p | number | å¦ | æ ¸é‡‡æ ·å‚æ•° |
| n | integer | å¦ | ç”Ÿæˆæ•°é‡ |
| stream | boolean | å¦ | æµå¼è¾“å‡º |
| stop | string/array | å¦ | åœæ­¢åºåˆ— |

### 3. åµŒå…¥å‘é‡ï¼ˆEmbeddingsï¼‰

å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡è¡¨ç¤ºã€‚

**è¯·æ±‚ç«¯ç‚¹**
```
POST /v1/embeddings
```

**è¯·æ±‚å‚æ•°**

| å‚æ•° | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|------|------|------|------|
| model | string | æ˜¯ | æ¨¡å‹åç§°ï¼Œå¦‚ `text-embedding-ada-002` |
| input | string/array | æ˜¯ | è¾“å…¥æ–‡æœ¬ |
| encoding_format | string | å¦ | ç¼–ç æ ¼å¼ï¼Œ`float` æˆ– `base64` |

**å®Œæ•´ä»£ç ç¤ºä¾‹**

<Tabs>
  <Tab title="cURL">
    ```bash
    curl -X POST "https://api.laozhang.ai/v1/embeddings" \
      -H "Authorization: Bearer YOUR_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "text-embedding-ada-002",
        "input": "è¿™æ˜¯ä¸€æ®µéœ€è¦å‘é‡åŒ–çš„æ–‡æœ¬ç¤ºä¾‹"
      }'
    ```
  </Tab>
  
  <Tab title="Python (SDK)">
    ```python
    from openai import OpenAI
    
    client = OpenAI(
        api_key="YOUR_API_KEY",
        base_url="https://api.laozhang.ai/v1"
    )
    
    response = client.embeddings.create(
        model="text-embedding-ada-002",
        input="è¿™æ˜¯ä¸€æ®µéœ€è¦å‘é‡åŒ–çš„æ–‡æœ¬ç¤ºä¾‹"
    )
    
    # è·å–å‘é‡
    embedding = response.data[0].embedding
    print(f"å‘é‡ç»´åº¦: {len(embedding)}")
    print(f"å‰5ä¸ªå€¼: {embedding[:5]}")
    ```
  </Tab>
  
  <Tab title="Python (requests)">
    ```python
    import requests
    import json
    
    url = "https://api.laozhang.ai/v1/embeddings"
    headers = {
        "Authorization": "Bearer YOUR_API_KEY",
        "Content-Type": "application/json"
    }
    
    data = {
        "model": "text-embedding-ada-002",
        "input": "è¿™æ˜¯ä¸€æ®µéœ€è¦å‘é‡åŒ–çš„æ–‡æœ¬ç¤ºä¾‹"
    }
    
    response = requests.post(url, headers=headers, json=data)
    result = response.json()
    
    if response.status_code == 200:
        embedding = result["data"][0]["embedding"]
        print(f"å‘é‡ç»´åº¦: {len(embedding)}")
        print(f"å‘é‡å€¼: {embedding[:5]}")  # æ˜¾ç¤ºå‰5ä¸ªå€¼
    else:
        print(f"é”™è¯¯: {result}")
    ```
  </Tab>
  
  <Tab title="Node.js">
    ```javascript
    const OpenAI = require('openai');
    
    const client = new OpenAI({
      apiKey: 'YOUR_API_KEY',
      baseURL: 'https://api.laozhang.ai/v1'
    });
    
    async function getEmbedding() {
      try {
        const response = await client.embeddings.create({
          model: 'text-embedding-ada-002',
          input: 'è¿™æ˜¯ä¸€æ®µéœ€è¦å‘é‡åŒ–çš„æ–‡æœ¬ç¤ºä¾‹'
        });
        
        const embedding = response.data[0].embedding;
        console.log(`å‘é‡ç»´åº¦: ${embedding.length}`);
        console.log(`å‰5ä¸ªå€¼: ${embedding.slice(0, 5)}`);
      } catch (error) {
        console.error('APIè°ƒç”¨é”™è¯¯:', error);
      }
    }
    
    getEmbedding();
    ```
  </Tab>
</Tabs>

### 4. å›¾åƒç”Ÿæˆï¼ˆImagesï¼‰

ç”Ÿæˆã€ç¼–è¾‘æˆ–å˜æ¢å›¾åƒã€‚

**ç”Ÿæˆå›¾åƒ**
```
POST /v1/images/generations
```

**è¯·æ±‚å‚æ•°**

| å‚æ•° | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|------|------|------|------|
| model | string | æ˜¯ | æ¨¡å‹åç§°ï¼Œæ¨è `gpt-image-1` |
| prompt | string | æ˜¯ | å›¾åƒæè¿°æç¤ºè¯ |
| n | integer | å¦ | ç”Ÿæˆæ•°é‡ï¼Œé»˜è®¤1 |
| size | string | å¦ | å›¾åƒå°ºå¯¸ï¼š`1024x1024`, `1792x1024`, `1024x1792` |
| quality | string | å¦ | è´¨é‡ï¼š`standard` æˆ– `hd` |
| style | string | å¦ | é£æ ¼ï¼š`vivid` æˆ– `natural` |

<Note>
æ¨èä½¿ç”¨ `gpt-image-1` æ¨¡å‹è¿›è¡Œå›¾åƒç”Ÿæˆã€‚æ›´å¤šå›¾åƒç”ŸæˆåŠŸèƒ½å’Œå‚æ•°è¯´æ˜ï¼Œè¯·æŸ¥çœ‹ [GPTå›¾åƒç”Ÿæˆè¯¦ç»†æ–‡æ¡£](/api-capabilities/gpt-image-1)ã€‚
</Note>

**å®Œæ•´ä»£ç ç¤ºä¾‹**

<Tabs>
  <Tab title="cURL">
    ```bash
    curl -X POST "https://api.laozhang.ai/v1/images/generations" \
      -H "Authorization: Bearer YOUR_API_KEY" \
      -H "Content-Type: application/json" \
      -d '{
        "model": "gpt-image-1",
        "prompt": "ä¸€åªå¯çˆ±çš„æ©™è‰²å°çŒ«ååœ¨é˜³å…‰æ˜åªšçš„èŠ±å›­é‡Œ",
        "n": 1,
        "size": "1024x1024",
        "quality": "hd"
      }'
    ```
  </Tab>
  
  <Tab title="Python (SDK)">
    ```python
    from openai import OpenAI
    
    client = OpenAI(
        api_key="YOUR_API_KEY",
        base_url="https://api.laozhang.ai/v1"
    )
    
    response = client.images.generate(
        model="gpt-image-1",  # æ¨èä½¿ç”¨gpt-image-1
        prompt="ä¸€åªå¯çˆ±çš„æ©™è‰²å°çŒ«ååœ¨é˜³å…‰æ˜åªšçš„èŠ±å›­é‡Œ",
        n=1,
        size="1024x1024",
        quality="hd"
    )
    
    # è·å–å›¾ç‰‡URL
    image_url = response.data[0].url
    print(f"ç”Ÿæˆçš„å›¾ç‰‡: {image_url}")
    
    # ä¸‹è½½å›¾ç‰‡
    import requests
    img_response = requests.get(image_url)
    with open("generated_image.png", "wb") as f:
        f.write(img_response.content)
    print("å›¾ç‰‡å·²ä¿å­˜ä¸º generated_image.png")
    ```
  </Tab>
  
  <Tab title="Node.js">
    ```javascript
    const OpenAI = require('openai');
    const fs = require('fs');
    
    const client = new OpenAI({
      apiKey: 'YOUR_API_KEY',
      baseURL: 'https://api.laozhang.ai/v1'
    });
    
    async function generateImage() {
      try {
        const response = await client.images.generate({
          model: 'gpt-image-1',  // æ¨èä½¿ç”¨gpt-image-1
          prompt: 'ä¸€åªå¯çˆ±çš„æ©™è‰²å°çŒ«ååœ¨é˜³å…‰æ˜åªšçš„èŠ±å›­é‡Œ',
          n: 1,
          size: '1024x1024',
          quality: 'hd'
        });
        
        const imageUrl = response.data[0].url;
        console.log('ç”Ÿæˆçš„å›¾ç‰‡:', imageUrl);
        
        // ä¸‹è½½å›¾ç‰‡
        const fetch = require('node-fetch');
        const imgResponse = await fetch(imageUrl);
        const buffer = await imgResponse.buffer();
        fs.writeFileSync('generated_image.png', buffer);
        console.log('å›¾ç‰‡å·²ä¿å­˜');
        
      } catch (error) {
        console.error('ç”Ÿæˆå›¾ç‰‡é”™è¯¯:', error);
      }
    }
    
    generateImage();
    ```
  </Tab>
</Tabs>

### 5. éŸ³é¢‘è½¬æ–‡å­—ï¼ˆAudioï¼‰

è¯­éŸ³è¯†åˆ«å’Œè½¬å½•ã€‚

**è½¬å½•éŸ³é¢‘**
```
POST /v1/audio/transcriptions
```

**è¯·æ±‚å‚æ•°**ï¼ˆForm-Dataï¼‰

| å‚æ•° | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|------|------|------|------|
| file | file | æ˜¯ | éŸ³é¢‘æ–‡ä»¶ |
| model | string | æ˜¯ | æ¨¡å‹åç§°ï¼Œå¦‚ `whisper-1` |
| language | string | å¦ | è¯­è¨€ä»£ç  |
| prompt | string | å¦ | æŒ‡å¯¼æç¤º |
| response_format | string | å¦ | å“åº”æ ¼å¼ |
| temperature | number | å¦ | é‡‡æ ·æ¸©åº¦ |

### 6. æ¨¡å‹åˆ—è¡¨

è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨ã€‚

**è¯·æ±‚ç«¯ç‚¹**
```
GET /v1/models
```

**å“åº”ç¤ºä¾‹**
```json
{
  "object": "list",
  "data": [
    {
      "id": "gpt-3.5-turbo",
      "object": "model",
      "created": 1677610602,
      "owned_by": "openai"
    },
    {
      "id": "gpt-4o",
      "object": "model",
      "created": 1687882411,
      "owned_by": "openai"
    }
  ]
}
```

## æµå¼å“åº”

### å¼€å¯æµå¼è¾“å‡º

åœ¨è¯·æ±‚ä¸­è®¾ç½® `stream: true`ï¼š

```json
{
  "model": "gpt-3.5-turbo",
  "messages": [{"role": "user", "content": "Hello"}],
  "stream": true
}
```

### æµå¼å“åº”æ ¼å¼

å“åº”å°†ä»¥ Server-Sent Events (SSE) æ ¼å¼è¿”å›ï¼š

```
data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1699000000,"model":"gpt-3.5-turbo","choices":[{"delta":{"content":"Hello"},"index":0}]}

data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1699000000,"model":"gpt-3.5-turbo","choices":[{"delta":{"content":" there"},"index":0}]}

data: [DONE]
```

### å¤„ç†æµå¼å“åº”

<Tabs>
  <Tab title="Python">
    ```python
    import requests
    import json
    
    response = requests.post(
        'https://api.laozhang.ai/v1/chat/completions',
        headers={
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json'
        },
        json={
            'model': 'gpt-3.5-turbo',
            'messages': [{'role': 'user', 'content': 'Hello'}],
            'stream': True
        },
        stream=True
    )
    
    for line in response.iter_lines():
        if line:
            line = line.decode('utf-8')
            if line.startswith('data: '):
                data = line[6:]
                if data != '[DONE]':
                    chunk = json.loads(data)
                    content = chunk['choices'][0]['delta'].get('content', '')
                    print(content, end='')
    ```
  </Tab>
  
  <Tab title="JavaScript">
    ```javascript
    const response = await fetch('https://api.laozhang.ai/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: 'gpt-3.5-turbo',
        messages: [{role: 'user', content: 'Hello'}],
        stream: true
      })
    });
    
    const reader = response.body.getReader();
    const decoder = new TextDecoder();
    
    while (true) {
      const {done, value} = await reader.read();
      if (done) break;
      
      const chunk = decoder.decode(value);
      const lines = chunk.split('\n');
      
      for (const line of lines) {
        if (line.startsWith('data: ')) {
          const data = line.slice(6);
          if (data !== '[DONE]') {
            const json = JSON.parse(data);
            const content = json.choices[0].delta.content || '';
            process.stdout.write(content);
          }
        }
      }
    }
    ```
  </Tab>
</Tabs>

## é”™è¯¯å¤„ç†

### é”™è¯¯å“åº”æ ¼å¼

```json
{
  "error": {
    "message": "Invalid API key provided",
    "type": "invalid_request_error",
    "param": null,
    "code": "invalid_api_key"
  }
}
```

### å¸¸è§é”™è¯¯ç 

| é”™è¯¯ç  | HTTPçŠ¶æ€ç  | è¯´æ˜ |
|--------|-----------|------|
| invalid_api_key | 401 | APIå¯†é’¥æ— æ•ˆ |
| insufficient_quota | 429 | é¢åº¦ä¸è¶³ |
| model_not_found | 404 | æ¨¡å‹ä¸å­˜åœ¨ |
| invalid_request_error | 400 | è¯·æ±‚å‚æ•°é”™è¯¯ |
| server_error | 500 | æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ |
| rate_limit_exceeded | 429 | è¯·æ±‚é¢‘ç‡è¿‡é«˜ |

### é”™è¯¯å¤„ç†ç¤ºä¾‹

```python
try:
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": "Hello"}]
    )
except Exception as e:
    if hasattr(e, 'status_code'):
        if e.status_code == 401:
            print("APIå¯†é’¥æ— æ•ˆ")
        elif e.status_code == 429:
            print("è¯·æ±‚è¿‡äºé¢‘ç¹æˆ–é¢åº¦ä¸è¶³")
        elif e.status_code == 500:
            print("æœåŠ¡å™¨é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•")
    else:
        print(f"æœªçŸ¥é”™è¯¯ï¼š{str(e)}")
```

## æœ€ä½³å®è·µ

### 1. è¯·æ±‚ä¼˜åŒ–

- **åˆç†è®¾ç½® max_tokens**ï¼šé¿å…ä¸å¿…è¦çš„é•¿è¾“å‡º
- **ä½¿ç”¨ temperature**ï¼šæ§åˆ¶è¾“å‡ºçš„éšæœºæ€§
- **æ‰¹é‡å¤„ç†**ï¼šåˆå¹¶å¤šä¸ªè¯·æ±‚å‡å°‘è°ƒç”¨æ¬¡æ•°

### 2. é”™è¯¯é‡è¯•

å®ç°æŒ‡æ•°é€€é¿çš„é‡è¯•æœºåˆ¶ï¼š

```python
import time
import random

def retry_with_backoff(func, max_retries=3):
    for i in range(max_retries):
        try:
            return func()
        except Exception as e:
            if i == max_retries - 1:
                raise e
            wait_time = (2 ** i) + random.uniform(0, 1)
            time.sleep(wait_time)
```

### 3. å®‰å…¨å»ºè®®

- **ä¿æŠ¤APIå¯†é’¥**ï¼šä½¿ç”¨ç¯å¢ƒå˜é‡å­˜å‚¨
- **é™åˆ¶æƒé™**ï¼šä¸ºä¸åŒåº”ç”¨åˆ›å»ºä¸åŒçš„å¯†é’¥
- **ç›‘æ§ä½¿ç”¨**ï¼šå®šæœŸæ£€æŸ¥APIä½¿ç”¨æ—¥å¿—

### 4. æ€§èƒ½ä¼˜åŒ–

- **ä½¿ç”¨æµå¼è¾“å‡º**ï¼šæå‡ç”¨æˆ·ä½“éªŒ
- **ç¼“å­˜å“åº”**ï¼šå¯¹ç›¸åŒè¯·æ±‚ç¼“å­˜ç»“æœ
- **å¹¶å‘æ§åˆ¶**ï¼šåˆç†æ§åˆ¶å¹¶å‘è¯·æ±‚æ•°

## é€Ÿç‡é™åˆ¶

è€å¼ API å®æ–½ä»¥ä¸‹é€Ÿç‡é™åˆ¶ï¼š

| é™åˆ¶ç±»å‹ | é™åˆ¶å€¼ | è¯´æ˜ |
|---------|--------|------|
| RPM (æ¯åˆ†é’Ÿè¯·æ±‚æ•°) | 3000 | æ¯ä¸ªAPIå¯†é’¥ |
| TPM (æ¯åˆ†é’Ÿä»¤ç‰Œæ•°) | 1000000 | æ¯ä¸ªAPIå¯†é’¥ |
| å¹¶å‘è¯·æ±‚æ•° | 100 | åŒæ—¶å¤„ç†çš„è¯·æ±‚ |

è¶…å‡ºé™åˆ¶æ—¶ä¼šè¿”å› 429 é”™è¯¯ï¼Œè¯·åˆç†æ§åˆ¶è¯·æ±‚é¢‘ç‡ã€‚

## éœ€è¦å¸®åŠ©ï¼Ÿ

- æŸ¥çœ‹ [å®Œæ•´APIæ–‡æ¡£](/api-reference/introduction)
- è®¿é—® [è€å¼ APIå®˜ç½‘](https://api.laozhang.ai)
- è”ç³»æŠ€æœ¯æ”¯æŒï¼šsupport@laozhang.ai

<Note>
æœ¬æ‰‹å†ŒæŒç»­æ›´æ–°ä¸­ï¼Œè¯·å…³æ³¨æœ€æ–°ç‰ˆæœ¬ä»¥è·å–æ–°åŠŸèƒ½å’Œæ”¹è¿›ã€‚
</Note>