---
title: éŸ³é¢‘è½¬å½•ä¸è¯­éŸ³åˆæˆ
sidebarTitle: éŸ³é¢‘ API
description: "STT/TTS APIï¼šéŸ³é¢‘è½¬æ–‡å­—å’Œæ–‡å­—è½¬è¯­éŸ³ã€‚æ”¯æŒ Whisperã€GPT-4o Transcribeã€TTS-1 HDã€‚å¤šè¯­è¨€è¯†åˆ«ï¼Œ6 ç§éŸ³è‰²å¯é€‰ã€‚"
icon: "mic"
---

## åŠŸèƒ½ç®€ä»‹

è€å¼ API æä¾›å¼ºå¤§çš„éŸ³é¢‘å¤„ç†èƒ½åŠ›ï¼ŒåŒ…æ‹¬éŸ³é¢‘è½¬æ–‡å­—ï¼ˆSpeech-to-Textï¼‰å’Œæ–‡å­—è½¬è¯­éŸ³ï¼ˆText-to-Speechï¼‰ä¸¤å¤§åŠŸèƒ½ã€‚é€šè¿‡ç»Ÿä¸€çš„ OpenAI API æ ¼å¼ï¼Œæ‚¨å¯ä»¥è½»æ¾å®ç°ä¼šè®®è®°å½•è½¬å½•ã€å­—å¹•ç”Ÿæˆã€è¯­éŸ³åŠ©æ‰‹ã€æœ‰å£°è¯»ç‰©åˆ¶ä½œç­‰åº”ç”¨ã€‚

<Note>
**ğŸ™ï¸ æ™ºèƒ½éŸ³é¢‘å¤„ç†**  
æ”¯æŒå¤šè¯­è¨€éŸ³é¢‘è½¬æ–‡å­—ã€é«˜æ¸…è¯­éŸ³åˆæˆã€å®æ—¶æµå¼è¾“å‡ºï¼Œè®© AI çœŸæ­£"å¬æ‡‚"å’Œ"è¯´å‡º"å†…å®¹ã€‚
</Note>

## ğŸŒŸ æ ¸å¿ƒç‰¹æ€§

- **ğŸ¯ å¤šæ¨¡å‹æ”¯æŒ**ï¼šGPT-4o Transcribeã€Whisperã€TTS-1/HD ç­‰ä¸“ä¸šéŸ³é¢‘æ¨¡å‹
- **ğŸŒ å¤šè¯­è¨€è¯†åˆ«**ï¼šæ”¯æŒ 50+ ç§è¯­è¨€çš„éŸ³é¢‘è½¬æ–‡å­—
- **ğŸ¤ é«˜è´¨é‡åˆæˆ**ï¼šæ”¯æŒæ ‡å‡†å’Œé«˜æ¸…ä¸¤ç§è¯­éŸ³è´¨é‡
- **ğŸ—£ï¸ å¤šç§éŸ³è‰²**ï¼š6 ç§ä¸åŒçš„è¯­éŸ³éŸ³è‰²å¯é€‰
- **âš¡ å¿«é€Ÿå“åº”**ï¼šé«˜æ€§èƒ½å¤„ç†ï¼Œç§’çº§è¿”å›ç»“æœ
- **ğŸ’° çµæ´»è®¡è´¹**ï¼šæŒ‰ Token æˆ–æ—¶é•¿è®¡è´¹ï¼Œæˆæœ¬å¯æ§

## ğŸ“‹ æ”¯æŒçš„éŸ³é¢‘æ¨¡å‹

### éŸ³é¢‘è½¬æ–‡å­—ï¼ˆSpeech-to-Textï¼‰

| æ¨¡å‹åç§° | æ¨¡å‹ ID | è®¡è´¹æ–¹å¼ | ç‰¹ç‚¹ |
|---------|---------|---------|------|
| **GPT-4o Transcribe** â­ | `gpt-4o-transcribe` | Token | é«˜å‡†ç¡®åº¦ï¼Œæ”¯æŒå¤šè¯­è¨€ |
| **GPT-4o Mini Transcribe** | `gpt-4o-mini-transcribe` | Token | å¿«é€Ÿé«˜æ•ˆï¼Œæˆæœ¬ä½ |
| **Whisper v1** | `whisper-1` | æ—¶é•¿ï¼ˆç§’ï¼‰ | OpenAI Whisper æ¨¡å‹ |

### æ–‡å­—è½¬è¯­éŸ³ï¼ˆText-to-Speechï¼‰

| æ¨¡å‹åç§° | æ¨¡å‹ ID | éŸ³è´¨ | ç‰¹ç‚¹ |
|---------|---------|------|------|
| **TTS-1** â­ | `tts-1` | æ ‡å‡†è´¨é‡ | å¿«é€Ÿç”Ÿæˆï¼Œé€‚åˆå®æ—¶åº”ç”¨ |
| **TTS-1 HD** | `tts-1-hd` | é«˜æ¸…è´¨é‡ | éŸ³è´¨æ›´ä½³ï¼Œé€‚åˆå†…å®¹åˆ›ä½œ |

### å¯ç”¨çš„è¯­éŸ³éŸ³è‰²

- **alloy** - ä¸­æ€§éŸ³è‰²ï¼Œæ¸…æ™°è‡ªç„¶
- **echo** - ç”·æ€§éŸ³è‰²ï¼Œæ²‰ç¨³æœ‰åŠ›
- **fable** - è‹±å¼å£éŸ³ï¼Œä¼˜é›…åŠ¨å¬
- **onyx** - æ·±æ²‰ç”·å£°ï¼Œé€‚åˆæ’­æŠ¥
- **nova** - å¥³æ€§éŸ³è‰²ï¼Œæ¸©æš–äº²åˆ‡
- **shimmer** - æŸ”å’Œå¥³å£°ï¼Œé€‚åˆæ—ç™½

## ğŸ™ï¸ éŸ³é¢‘è½¬æ–‡å­—

### 1. åŸºç¡€ç¤ºä¾‹ - cURL

```bash
curl -X POST "https://api.laozhang.ai/v1/audio/transcriptions" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@audio.mp3" \
  -F "model=gpt-4o-transcribe"
```

**å“åº”ç¤ºä¾‹**ï¼š
```json
{
  "text": "ä½ å¥½ï¼Œè¿™æ˜¯ä¸€æ®µæµ‹è¯•è¯­éŸ³",
  "usage": {
    "type": "tokens",
    "total_tokens": 32,
    "input_tokens": 23,
    "output_tokens": 9
  }
}
```

### 2. Python ç¤ºä¾‹ - ä½¿ç”¨ OpenAI SDK

```python
from openai import OpenAI

client = OpenAI(
    api_key="YOUR_API_KEY",
    base_url="https://api.laozhang.ai/v1"
)

# æ–¹å¼ 1ï¼šç›´æ¥ä¼ æ–‡ä»¶è·¯å¾„
with open("audio.mp3", "rb") as audio_file:
    transcript = client.audio.transcriptions.create(
        model="gpt-4o-transcribe",
        file=audio_file
    )

print(transcript.text)
```

### 3. æŒ‡å®šè¯­è¨€å’Œå“åº”æ ¼å¼

```python
from openai import OpenAI

client = OpenAI(
    api_key="YOUR_API_KEY",
    base_url="https://api.laozhang.ai/v1"
)

with open("audio.mp3", "rb") as audio_file:
    transcript = client.audio.transcriptions.create(
        model="whisper-1",
        file=audio_file,
        language="zh",  # æŒ‡å®šè¯­è¨€ï¼šä¸­æ–‡
        response_format="json"  # å¯é€‰ï¼šjson, text, srt, vtt, verbose_json
    )

print(transcript.text)
```

### 4. ä½¿ç”¨ Whisper æ¨¡å‹ï¼ˆæŒ‰æ—¶é•¿è®¡è´¹ï¼‰

```bash
curl -X POST "https://api.laozhang.ai/v1/audio/transcriptions" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@audio.wav" \
  -F "model=whisper-1" \
  -F "language=zh"
```

**å“åº”ç¤ºä¾‹**ï¼š
```json
{
  "text": "ä½ å¥½,è¿™æ˜¯ä¸€æ®µæµ‹è¯•è¯­éŸ³",
  "usage": {
    "type": "duration",
    "seconds": 3
  }
}
```

### æ”¯æŒçš„éŸ³é¢‘æ ¼å¼

æ”¯æŒä»¥ä¸‹éŸ³é¢‘æ ¼å¼ï¼ˆæ–‡ä»¶å¤§å°é™åˆ¶ 25 MBï¼‰ï¼š
- **mp3** - MP3 éŸ³é¢‘æ–‡ä»¶
- **mp4** - MP4 éŸ³é¢‘æ–‡ä»¶
- **mpeg** - MPEG éŸ³é¢‘æ–‡ä»¶
- **mpga** - MPEG éŸ³é¢‘æ–‡ä»¶
- **m4a** - M4A éŸ³é¢‘æ–‡ä»¶
- **wav** - WAV éŸ³é¢‘æ–‡ä»¶
- **webm** - WebM éŸ³é¢‘æ–‡ä»¶

## ğŸ—£ï¸ æ–‡å­—è½¬è¯­éŸ³

### 1. åŸºç¡€ç¤ºä¾‹ - cURL

```bash
curl -X POST "https://api.laozhang.ai/v1/audio/speech" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "tts-1",
    "input": "ä½ å¥½ï¼Œæ¬¢è¿ä½¿ç”¨è€å¼ APIçš„è¯­éŸ³åˆæˆåŠŸèƒ½ã€‚",
    "voice": "alloy"
  }' \
  --output speech.mp3
```

### 2. Python ç¤ºä¾‹ - ç”Ÿæˆè¯­éŸ³æ–‡ä»¶

```python
from openai import OpenAI
from pathlib import Path

client = OpenAI(
    api_key="YOUR_API_KEY",
    base_url="https://api.laozhang.ai/v1"
)

response = client.audio.speech.create(
    model="tts-1",
    voice="nova",
    input="è¿™æ˜¯ä¸€æ®µéœ€è¦è½¬æ¢ä¸ºè¯­éŸ³çš„æ–‡å­—å†…å®¹ã€‚"
)

# ä¿å­˜ä¸º MP3 æ–‡ä»¶
response.stream_to_file("output.mp3")
```

### 3. ä½¿ç”¨é«˜æ¸…æ¨¡å‹

```python
from openai import OpenAI

client = OpenAI(
    api_key="YOUR_API_KEY",
    base_url="https://api.laozhang.ai/v1"
)

response = client.audio.speech.create(
    model="tts-1-hd",  # ä½¿ç”¨é«˜æ¸…æ¨¡å‹
    voice="shimmer",
    input="ä½¿ç”¨é«˜æ¸…æ¨¡å‹å¯ä»¥è·å¾—æ›´å¥½çš„éŸ³è´¨æ•ˆæœã€‚",
    speed=1.0  # è¯­é€Ÿï¼š0.25 åˆ° 4.0ï¼Œé»˜è®¤ 1.0
)

response.stream_to_file("speech_hd.mp3")
```

### 4. è°ƒæ•´è¯­é€Ÿ

```python
# å¿«é€Ÿæ’­æ”¾ï¼ˆ1.5 å€é€Ÿï¼‰
response = client.audio.speech.create(
    model="tts-1",
    voice="onyx",
    input="è¿™æ®µå†…å®¹ä¼šä»¥ 1.5 å€é€Ÿæ’­æ”¾ã€‚",
    speed=1.5
)

response.stream_to_file("speech_fast.mp3")
```

### 5. å®æ—¶æµå¼è¾“å‡º

```python
from openai import OpenAI

client = OpenAI(
    api_key="YOUR_API_KEY",
    base_url="https://api.laozhang.ai/v1"
)

response = client.audio.speech.create(
    model="tts-1",
    voice="alloy",
    input="å®æ—¶æµå¼è¾“å‡ºå¯ä»¥è¾¹ç”Ÿæˆè¾¹æ’­æ”¾ï¼Œæä¾›æ›´å¥½çš„ç”¨æˆ·ä½“éªŒã€‚"
)

# æµå¼å¤„ç†éŸ³é¢‘æ•°æ®
response.stream_to_file("streaming_speech.mp3")
```

## ğŸ¯ å¸¸è§åº”ç”¨åœºæ™¯

### 1. ä¼šè®®è®°å½•è½¬å½•

```python
from openai import OpenAI

client = OpenAI(
    api_key="YOUR_API_KEY",
    base_url="https://api.laozhang.ai/v1"
)

# è½¬å½•ä¼šè®®å½•éŸ³
with open("meeting.mp3", "rb") as audio_file:
    transcript = client.audio.transcriptions.create(
        model="gpt-4o-transcribe",
        file=audio_file,
        response_format="text"
    )

# ä¿å­˜ä¸ºæ–‡æœ¬æ–‡ä»¶
with open("meeting_transcript.txt", "w", encoding="utf-8") as f:
    f.write(transcript.text)
```

### 2. è§†é¢‘å­—å¹•ç”Ÿæˆ

```python
from openai import OpenAI

client = OpenAI(
    api_key="YOUR_API_KEY",
    base_url="https://api.laozhang.ai/v1"
)

# ç”Ÿæˆ SRT å­—å¹•æ–‡ä»¶
with open("video_audio.mp3", "rb") as audio_file:
    transcript = client.audio.transcriptions.create(
        model="whisper-1",
        file=audio_file,
        response_format="srt"  # SRT å­—å¹•æ ¼å¼
    )

# ä¿å­˜å­—å¹•æ–‡ä»¶
with open("subtitles.srt", "w", encoding="utf-8") as f:
    f.write(transcript.text)
```

### 3. å¤šè¯­è¨€å†…å®¹æ’­æŠ¥

```python
from openai import OpenAI

client = OpenAI(
    api_key="YOUR_API_KEY",
    base_url="https://api.laozhang.ai/v1"
)

# ç”Ÿæˆå¤šç§è¯­è¨€çš„è¯­éŸ³
texts = {
    "ä¸­æ–‡": "æ¬¢è¿ä½¿ç”¨è€å¼ API",
    "English": "Welcome to LaoZhang API",
    "æ—¥æœ¬èª": "ã‚ˆã†ã“ã"
}

for lang, text in texts.items():
    response = client.audio.speech.create(
        model="tts-1",
        voice="nova",
        input=text
    )
    response.stream_to_file(f"welcome_{lang}.mp3")
```

### 4. æœ‰å£°è¯»ç‰©åˆ¶ä½œ

```python
from openai import OpenAI

client = OpenAI(
    api_key="YOUR_API_KEY",
    base_url="https://api.laozhang.ai/v1"
)

# å°†é•¿ç¯‡æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³
with open("book_chapter.txt", "r", encoding="utf-8") as f:
    text = f.read()

# åˆ†æ®µå¤„ç†ï¼ˆTTS æœ‰å­—ç¬¦é™åˆ¶ï¼‰
max_chars = 4096
segments = [text[i:i+max_chars] for i in range(0, len(text), max_chars)]

for idx, segment in enumerate(segments):
    response = client.audio.speech.create(
        model="tts-1-hd",  # ä½¿ç”¨é«˜æ¸…æ¨¡å‹
        voice="fable",  # é€‚åˆæœ—è¯»çš„éŸ³è‰²
        input=segment
    )
    response.stream_to_file(f"audiobook_part_{idx+1}.mp3")
```

## ğŸ’¡ æœ€ä½³å®è·µ

### éŸ³é¢‘è½¬æ–‡å­—ä¼˜åŒ–

1. **éŸ³é¢‘è´¨é‡**ï¼š
   - é‡‡æ ·ç‡å»ºè®® â‰¥16 kHz
   - é™ä½èƒŒæ™¯å™ªéŸ³å¯æé«˜è¯†åˆ«å‡†ç¡®åº¦
   - æ¸…æ™°çš„äººå£°å½•éŸ³æ•ˆæœæœ€ä½³

2. **æ–‡ä»¶å¤§å°**ï¼š
   - å•ä¸ªæ–‡ä»¶ â‰¤25 MB
   - è¶…å¤§æ–‡ä»¶å»ºè®®å…ˆåˆ†æ®µå¤„ç†

3. **è¯­è¨€æŒ‡å®š**ï¼š
   - æ˜ç¡®æŒ‡å®šè¯­è¨€å¯æé«˜å‡†ç¡®åº¦
   - æ”¯æŒçš„è¯­è¨€ä»£ç ï¼šzhï¼ˆä¸­æ–‡ï¼‰ã€enï¼ˆè‹±æ–‡ï¼‰ã€jaï¼ˆæ—¥è¯­ï¼‰ç­‰

4. **å“åº”æ ¼å¼é€‰æ‹©**ï¼š
   - `json`ï¼šé»˜è®¤æ ¼å¼ï¼ŒåŒ…å«å®Œæ•´ä¿¡æ¯
   - `text`ï¼šçº¯æ–‡æœ¬è¾“å‡º
   - `srt`/`vtt`ï¼šå¸¦æ—¶é—´æˆ³çš„å­—å¹•æ ¼å¼
   - `verbose_json`ï¼šè¯¦ç»† JSONï¼ŒåŒ…å«æ—¶é—´æˆ³å’Œè¯çº§ä¿¡æ¯

### æ–‡å­—è½¬è¯­éŸ³ä¼˜åŒ–

1. **éŸ³è‰²é€‰æ‹©**ï¼š
   - `alloy`/`nova`ï¼šé€‚åˆé€šç”¨åœºæ™¯
   - `echo`/`onyx`ï¼šé€‚åˆæ–°é—»æ’­æŠ¥
   - `fable`/`shimmer`ï¼šé€‚åˆæ•…äº‹æœ—è¯»

2. **è¯­é€Ÿè°ƒæ•´**ï¼š
   - æ­£å¸¸è¯­é€Ÿï¼š1.0
   - å¿«é€Ÿæ’­æŠ¥ï¼š1.2 - 1.5
   - æ…¢é€Ÿæ•™å­¦ï¼š0.75 - 0.9

3. **æ–‡æœ¬ä¼˜åŒ–**ï¼š
   - å•æ¬¡è¯·æ±‚æ–‡æœ¬ â‰¤4096 å­—ç¬¦
   - ä½¿ç”¨æ ‡ç‚¹ç¬¦å·æ§åˆ¶åœé¡¿å’Œè¯­è°ƒ
   - æ•°å­—å’Œç‰¹æ®Šç¬¦å·å»ºè®®è½¬æ¢ä¸ºæ–‡å­—

4. **æˆæœ¬æ§åˆ¶**ï¼š
   - æ ‡å‡†åœºæ™¯ä½¿ç”¨ `tts-1`
   - é«˜è´¨é‡éœ€æ±‚ä½¿ç”¨ `tts-1-hd`
   - æ ¹æ®å®é™…éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ¨¡å‹

### é”™è¯¯å¤„ç†

```python
from openai import OpenAI
import time

client = OpenAI(
    api_key="YOUR_API_KEY",
    base_url="https://api.laozhang.ai/v1"
)

def transcribe_with_retry(audio_file_path, max_retries=3):
    """å¸¦é‡è¯•æœºåˆ¶çš„éŸ³é¢‘è½¬æ–‡å­—å‡½æ•°"""
    for attempt in range(max_retries):
        try:
            with open(audio_file_path, "rb") as audio_file:
                transcript = client.audio.transcriptions.create(
                    model="gpt-4o-transcribe",
                    file=audio_file
                )
            return transcript.text
        except Exception as e:
            print(f"å°è¯• {attempt + 1}/{max_retries} å¤±è´¥: {e}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
            else:
                raise
    return None
```

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### éŸ³é¢‘è½¬æ–‡å­—æ¨¡å‹å¯¹æ¯”

| æ¨¡å‹ | å‡†ç¡®åº¦ | é€Ÿåº¦ | æ”¯æŒè¯­è¨€ | è®¡è´¹æ–¹å¼ | ä»·æ ¼ |
|------|--------|------|---------|---------|------|
| gpt-4o-transcribe | â­â­â­â­â­ | â­â­â­â­ | 50+ | Token | $$ |
| gpt-4o-mini-transcribe | â­â­â­â­ | â­â­â­â­â­ | 50+ | Token | $ |
| whisper-1 | â­â­â­â­ | â­â­â­ | 50+ | æ—¶é•¿ | $ |

### æ–‡å­—è½¬è¯­éŸ³æ¨¡å‹å¯¹æ¯”

| æ¨¡å‹ | éŸ³è´¨ | é€Ÿåº¦ | è‡ªç„¶åº¦ | ä»·æ ¼ |
|------|------|------|--------|------|
| tts-1 | â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | $ |
| tts-1-hd | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ | $$ |

## ğŸš¨ æ³¨æ„äº‹é¡¹

1. **éšç§ä¿æŠ¤**ï¼šä¸è¦ä¸Šä¼ åŒ…å«æ•æ„Ÿä¿¡æ¯çš„éŸ³é¢‘æ–‡ä»¶
2. **åˆè§„ä½¿ç”¨**ï¼šéµå®ˆç›¸å…³æ³•å¾‹æ³•è§„ï¼Œä¸ç”¨äºéæ³•ç”¨é€”
3. **ç‰ˆæƒå£°æ˜**ï¼šç”Ÿæˆçš„è¯­éŸ³å†…å®¹éœ€æ³¨æ˜ç”± AI ç”Ÿæˆ
4. **æ–‡ä»¶é™åˆ¶**ï¼šéŸ³é¢‘æ–‡ä»¶æœ€å¤§ 25 MBï¼Œæ–‡æœ¬æœ€é•¿ 4096 å­—ç¬¦
5. **ä½¿ç”¨é™åˆ¶**ï¼šè¯·å‹¿ç”¨äºå†’å……ä»–äººèº«ä»½æˆ–è™šå‡ä¿¡æ¯ä¼ æ’­

## ğŸ”— ç›¸å…³èµ„æº

- [Chat Completions API](/api-reference/chat-completions) - äº†è§£æ›´å¤šå…³äºå¯¹è¯ API çš„ä¿¡æ¯
- [API å®šä»·è¯´æ˜](https://api.laozhang.ai/account/pricing) - æŸ¥çœ‹è¯¦ç»†ä»·æ ¼ä¿¡æ¯

<Note>
ğŸ’¡ **å°è´´å£«**ï¼šå»ºè®®å…ˆä½¿ç”¨ `gpt-4o-mini-transcribe` æˆ– `tts-1` è¿›è¡Œæµ‹è¯•ï¼Œç¡®è®¤æ•ˆæœåå†ä½¿ç”¨é«˜çº§æ¨¡å‹è¿›è¡Œç”Ÿäº§éƒ¨ç½²ã€‚
</Note>

