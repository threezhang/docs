---
title: 文本生成（对话补全）
sidebarTitle: 文本生成 API
description: "Chat Completions API：支持 GPT-5、Claude 4、Gemini 2.5 等 200+ 大模型。单轮/多轮对话、角色扮演、代码生成。OpenAI 兼容格式。"
icon: "message-square"
---

## 功能概述

文本生成（Chat Completions）是老张API最核心的能力之一，支持调用 200+ 热门 AI 大模型进行智能对话和文本生成。通过统一的 OpenAI 兼容接口，你可以轻松实现：

- **智能对话**：构建聊天机器人、虚拟助手
- **内容创作**：文章写作、创意生成、文案润色
- **代码辅助**：代码生成、调试、重构建议
- **知识问答**：回答问题、知识检索、信息提取
- **角色扮演**：定制化 AI 角色、场景模拟

<Info>
  支持 GPT-5、Claude 4、Gemini 2.5、DeepSeek、Qwen 等 200+ 主流大模型，一个 API Key 调用所有模型。
</Info>

## 快速开始

### 基础对话示例

使用 Chat Completions API 进行简单的单轮对话：

```python
from openai import OpenAI

client = OpenAI(
    api_key="sk-你的老张API密钥",
    base_url="https://api.laozhang.ai/v1"
)

response = client.chat.completions.create(
    model="gpt-4.1",
    messages=[
        {"role": "user", "content": "介绍一下人工智能的发展历程"}
    ]
)

print(response.choices[0].message.content)
```

### 多轮对话示例

通过 `messages` 数组维护对话历史，实现上下文连贯的多轮对话：

```python
from openai import OpenAI

client = OpenAI(
    api_key="sk-你的老张API密钥",
    base_url="https://api.laozhang.ai/v1"
)

messages = [
    {"role": "system", "content": "你是一个专业的 Python 编程助手"},
    {"role": "user", "content": "如何读取 CSV 文件？"},
    {"role": "assistant", "content": "可以使用 pandas 库的 read_csv() 函数..."},
    {"role": "user", "content": "那如何过滤特定列的数据？"}
]

response = client.chat.completions.create(
    model="gpt-4.1",
    messages=messages
)

print(response.choices[0].message.content)
```

## 核心参数详解

### model（必填）

指定要使用的模型名称，详见 [模型信息](/api-capabilities/model-info) 页面。

```python
model="gpt-5"              # GPT-5 最新
model="gpt-4.1"            # GPT-4.1 快速
model="claude-sonnet-4-20250514"  # Claude 4 Sonnet
model="gemini-2.5-pro"     # Gemini 2.5 Pro
model="deepseek-chat"      # DeepSeek Chat
```

### messages（必填）

对话消息数组，每条消息包含 `role` 和 `content` 字段：

<CardGroup cols={3}>
  <Card title="system" icon="gear">
    系统提示，定义 AI 的行为和角色
  </Card>
  <Card title="user" icon="user">
    用户消息，代表用户的输入
  </Card>
  <Card title="assistant" icon="robot">
    助手消息，代表 AI 的回复
  </Card>
</CardGroup>

```python
messages = [
    {"role": "system", "content": "你是一个友好的客服助手"},
    {"role": "user", "content": "我想咨询退款问题"},
    {"role": "assistant", "content": "好的，请问您遇到了什么问题？"},
    {"role": "user", "content": "商品有质量问题"}
]
```

### temperature（可选）

控制输出的随机性，范围 `0.0 ~ 2.0`，默认 `1.0`：

| 范围 | 特点 | 适用场景 |
|------|------|----------|
| **0.0 ~ 0.3** | 输出更确定、一致 | 翻译、总结、代码生成 |
| **0.7 ~ 1.0** | 平衡创造性和准确性 | 日常对话 |
| **1.0 ~ 2.0** | 输出更有创意、多样性 | 创意写作、头脑风暴 |

```python
response = client.chat.completions.create(
    model="gpt-4.1",
    messages=[{"role": "user", "content": "写一首关于春天的诗"}],
    temperature=1.2  # 提高创造性
)
```

### max_tokens（可选）

限制生成的最大 token 数量，用于控制成本和响应长度：

```python
response = client.chat.completions.create(
    model="gpt-4.1",
    messages=[{"role": "user", "content": "用一句话介绍 AI"}],
    max_tokens=50  # 限制输出长度
)
```

### stream（可选）

启用流式输出，逐 token 返回结果，提升用户体验：

```python
response = client.chat.completions.create(
    model="gpt-4.1",
    messages=[{"role": "user", "content": "写一篇关于人工智能的文章"}],
    stream=True
)

for chunk in response:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="")
```

## 高级用法

### 系统提示（System Prompt）

通过 `system` 角色定义 AI 的行为、角色、知识范围和回复风格：

```python
messages = [
    {
        "role": "system",
        "content": """你是一个专业的法律顾问助手。

规则：
1. 提供准确、专业的法律建议
2. 使用通俗易懂的语言解释法律术语
3. 必要时引用相关法律条文
4. 避免给出绝对性的结论，建议咨询专业律师
5. 保持中立、客观的立场"""
    },
    {"role": "user", "content": "请问劳动合同可以随时解除吗？"}
]
```

### 角色扮演

创建具有特定性格和专业领域的 AI 助手：

```python
messages = [
    {
        "role": "system",
        "content": "你是一位资深的 Python 开发者，拥有 10 年经验。你擅长用简洁的代码解决问题，喜欢使用 Pythonic 的写法，并且会主动指出代码中的潜在问题。"
    },
    {"role": "user", "content": "帮我写一个快速排序算法"}
]
```

### 上下文管理

对于长对话，需要合理管理上下文长度，避免超过模型的 token 限制：

```python
def manage_context(messages, max_history=10):
    """保留最近的对话历史"""
    # 保留 system 消息
    system_messages = [m for m in messages if m["role"] == "system"]
    # 保留最近的 N 条对话
    recent_messages = messages[-max_history:]
    
    return system_messages + recent_messages

# 使用示例
messages = manage_context(messages, max_history=10)
```

## 推荐模型

| 场景 | 推荐模型 | 原因 |
|------|----------|------|
| 日常对话 | `gpt-4.1-mini`, `deepseek-chat` | 响应快、成本低 |
| 复杂推理 | `gpt-5`, `claude-sonnet-4-20250514` | 能力强、准确度高 |
| 代码生成 | `claude-sonnet-4-20250514`, `deepseek-coder` | 代码能力优秀 |
| 长文本 | `gemini-2.5-pro`, `claude-3-opus` | 支持超长上下文 |
| 多语言 | `gpt-4.1`, `gemini-2.5-pro` | 多语言支持好 |

## 最佳实践

### 1. 优化提示词

```python
# ❌ 不好的提示词
"写一篇文章"

# ✅ 好的提示词
"""请写一篇关于人工智能在医疗领域应用的科普文章。

要求：
- 长度：800-1000 字
- 受众：普通读者
- 结构：引言、应用场景、案例分析、未来展望
- 语气：专业但易懂
- 包含 2-3 个真实案例"""
```

### 2. 错误处理

```python
from openai import OpenAI, OpenAIError
import time

def chat_with_retry(messages, max_retries=3):
    """带重试机制的聊天函数"""
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                model="gpt-4.1",
                messages=messages
            )
            return response.choices[0].message.content
        except OpenAIError as e:
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)  # 指数退避
                continue
            else:
                raise

# 使用示例
try:
    result = chat_with_retry(messages)
    print(result)
except OpenAIError as e:
    print(f"API 调用失败：{e}")
```

### 3. 控制成本

```python
# 使用性价比更高的模型
response = client.chat.completions.create(
    model="gpt-4.1-mini",  # 轻量模型
    messages=messages,
    max_tokens=500,  # 限制最大输出
    temperature=0.7
)

# 定期清理对话历史
if len(messages) > 20:
    messages = messages[-10:]  # 只保留最近 10 条
```

## 常见问题

<AccordionGroup>
  <Accordion title="如何计算 token 数量？">
    使用 `tiktoken` 库估算：

    ```python
    import tiktoken

    def count_tokens(text, model="gpt-4"):
        encoding = tiktoken.encoding_for_model(model)
        return len(encoding.encode(text))

    tokens = count_tokens("你好，世界！")
    print(f"Token 数量：{tokens}")
    ```
  </Accordion>

  <Accordion title="为什么输出被截断了？">
    可能原因：
    1. 达到了 `max_tokens` 限制
    2. 模型的上下文窗口不足
    3. 触发了内容安全策略

    检查 `finish_reason` 字段：
    ```python
    finish_reason = response.choices[0].finish_reason
    if finish_reason == "length":
        print("输出因长度限制被截断")
    ```
  </Accordion>

  <Accordion title="如何实现对话记忆？">
    在应用层维护对话历史数组，每次请求时传入完整的 messages。
  </Accordion>
</AccordionGroup>

## 相关文档

<CardGroup cols={2}>
  <Card title="模型信息" icon="database" href="/api-capabilities/model-info">
    查看支持的所有模型及定价
  </Card>
  <Card title="文本嵌入" icon="vector-square" href="/api-capabilities/text-embedding">
    将文本转换为向量表示
  </Card>
  <Card title="API 参考" icon="code" href="/api-reference/chat-completions">
    Chat Completions API 详细参考
  </Card>
  <Card title="OpenAI SDK" icon="plug" href="/api-capabilities/openai-sdk">
    使用 OpenAI SDK 快速接入
  </Card>
</CardGroup>

