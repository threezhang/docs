---
title: Text Embedding
sidebarTitle: Embedding API
description: Convert text to vector representations for semantic search, text classification, and similarity computation
icon: "brackets-square"
---

## Overview

Text Embedding API converts text into high-dimensional vector representations that capture semantic information. These vectors can be used for:

- **Semantic Search**: Search by meaning rather than keyword matching
- **Text Classification**: Automatically categorize text
- **Similarity Computation**: Calculate semantic similarity between texts
- **Clustering**: Automatically group similar texts
- **Recommendations**: Content-based similarity recommendations
- **RAG Applications**: Core capability for Retrieval-Augmented Generation

<Info>
  LaoZhang API supports OpenAI, Cohere, BGE and other embedding models, compatible with OpenAI SDK.
</Info>

## Quick Start

### Basic Example

```python
from openai import OpenAI

client = OpenAI(
    api_key="sk-your-laozhang-api-key",
    base_url="https://api.laozhang.ai/v1"
)

response = client.embeddings.create(
    model="text-embedding-3-small",
    input="Artificial intelligence is changing the world"
)

embedding = response.data[0].embedding
print(f"Dimensions: {len(embedding)}")
print(f"First 5 values: {embedding[:5]}")
```

### Batch Processing

```python
texts = [
    "Machine learning is a branch of AI",
    "Deep learning uses neural networks",
    "NLP enables machines to understand human language"
]

response = client.embeddings.create(
    model="text-embedding-3-small",
    input=texts
)

embeddings = [item.embedding for item in response.data]
print(f"Processed {len(embeddings)} texts")
```

## Supported Models

| Model | Dimensions | Features | Recommended For |
|-------|------------|----------|-----------------|
| `text-embedding-3-small` | 1536 | Cost-effective, fast | General use |
| `text-embedding-3-large` | 3072 | Best quality | High precision needs |
| `text-embedding-ada-002` | 1536 | Classic, compatible | Migration |

## Practical Examples

### 1. Text Similarity

```python
import numpy as np

def cosine_similarity(a, b):
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

text1 = "The weather is nice today"
text2 = "It's a sunny day"
text3 = "I like apples"

emb1 = get_embedding(text1)
emb2 = get_embedding(text2)
emb3 = get_embedding(text3)

print(f"Text1 vs Text2: {cosine_similarity(emb1, emb2):.4f}")
print(f"Text1 vs Text3: {cosine_similarity(emb1, emb3):.4f}")
```

### 2. Semantic Search

```python
documents = [
    "Python is an interpreted programming language",
    "JavaScript is commonly used for web development",
    "Machine learning is a branch of AI",
]

def semantic_search(query, docs, doc_embeddings, top_k=3):
    query_embedding = get_embedding(query)
    
    similarities = []
    for i, doc_emb in enumerate(doc_embeddings):
        sim = cosine_similarity(query_embedding, doc_emb)
        similarities.append((i, sim))
    
    similarities.sort(key=lambda x: x[1], reverse=True)
    return [(docs[i], sim) for i, sim in similarities[:top_k]]

# Search
results = semantic_search("What is AI?", documents, doc_embeddings)
```

## Best Practices

### 1. Batch Processing

```python
# ❌ Bad: Individual requests
for text in texts:
    embedding = get_embedding(text)

# ✅ Good: Batch request
embeddings = get_embeddings(texts)
```

### 2. Caching

```python
embedding_cache = {}

def get_embedding_cached(text):
    cache_key = hashlib.md5(text.encode()).hexdigest()
    if cache_key in embedding_cache:
        return embedding_cache[cache_key]
    
    embedding = get_embedding(text)
    embedding_cache[cache_key] = embedding
    return embedding
```

## Related Documentation

<CardGroup cols={2}>
  <Card title="Text Generation" icon="message-square" href="/en/api-capabilities/text-generation">
    Chat API documentation
  </Card>
  <Card title="LangChain" icon="link" href="/en/scenarios/engineering/langchain">
    Use Embedding with LangChain
  </Card>
  <Card title="Model Info" icon="database" href="/en/api-capabilities/model-info">
    View all supported models
  </Card>
  <Card title="Dify Setup" icon="puzzle" href="/en/scenarios/engineering/dify">
    Configure in Dify
  </Card>
</CardGroup>

