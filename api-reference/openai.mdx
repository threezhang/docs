---
title: 'OpenAI æ¨¡å‹'
sidebarTitle: 'OpenAI'
description: 'GPT-4oã€GPT-4ã€O1ç³»åˆ—æ¨¡å‹çš„è¯¦ç»†ä½¿ç”¨æŒ‡å—'
---

## æ¨¡å‹ç®€ä»‹

OpenAIæ˜¯å…¨çƒé¢†å…ˆçš„AIå…¬å¸ï¼Œå…¶GPTç³»åˆ—æ¨¡å‹åœ¨è€å¼ APIå¹³å°ä¸Šå®Œå…¨å¯ç”¨ã€‚æœ¬æŒ‡å—å°†è¯¦ç»†ä»‹ç»å¦‚ä½•ä½¿ç”¨GPT-4oã€GPT-4ã€O1ç­‰ç³»åˆ—æ¨¡å‹ï¼Œå¸®åŠ©ä½ å……åˆ†å‘æŒ¥è¿™äº›é¡¶çº§AIæ¨¡å‹çš„èƒ½åŠ›ã€‚

## ğŸš€ æ¨¡å‹æ¦‚è§ˆ

<CardGroup cols={2}>
  <Card
    title="GPT-4oç³»åˆ—"
    icon="openai"
    href="#gpt-4o-series"
  >
    æœ€æ–°å¤šæ¨¡æ€æ¨¡å‹ï¼Œæ”¯æŒæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘
  </Card>
  <Card
    title="GPT-4ç³»åˆ—"
    icon="brain"
    href="#gpt-4-series"
  >
    ç»å…¸å¼ºå¤§æ¨¡å‹ï¼Œä¼˜ç§€çš„æ¨ç†å’Œåˆ›ä½œèƒ½åŠ›
  </Card>
  <Card
    title="O1ç³»åˆ—"
    icon="calculator"
    href="#o1-series"
  >
    ä¸“ä¸ºå¤æ‚æ¨ç†è®¾è®¡çš„æ¨¡å‹
  </Card>
  <Card
    title="GPT-3.5ç³»åˆ—"
    icon="zap"
    href="#gpt-3-5-series"
  >
    é«˜æ€§ä»·æ¯”é€‰æ‹©ï¼Œé€‚åˆå¤§è§„æ¨¡åº”ç”¨
  </Card>
</CardGroup>

## GPT-4o ç³»åˆ—

GPT-4oæ˜¯OpenAIæœ€æ–°çš„æ——èˆ°æ¨¡å‹ï¼Œ"o"ä»£è¡¨"omni"ï¼ˆå…¨èƒ½ï¼‰ï¼Œæ”¯æŒæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ç­‰å¤šç§æ¨¡æ€ã€‚

### ğŸ”¥ GPT-4o (æ¨è)

**æ¨¡å‹IDï¼š** `gpt-4o`

**ç‰¹ç‚¹ï¼š**
- ğŸ¯ æœ€æ–°æ——èˆ°æ¨¡å‹ï¼Œæ€§èƒ½æœ€å¼º
- ğŸ–¼ï¸ æ”¯æŒå›¾åƒç†è§£å’Œç”Ÿæˆ
- ğŸ”Š æ”¯æŒéŸ³é¢‘è¾“å…¥è¾“å‡º
- ğŸŒ ä¼˜ç§€çš„å¤šè¯­è¨€èƒ½åŠ›
- âš¡ å“åº”é€Ÿåº¦å¿«

**ä»·æ ¼ï¼š** è¾“å…¥ $5/1M tokensï¼Œè¾“å‡º $15/1M tokens

<CodeGroup>

```python Python
from openai import OpenAI

client = OpenAI(
    api_key="YOUR_API_KEY",
    base_url="https://api.laozhang.ai/v1"
)

# åŸºç¡€æ–‡æœ¬å¯¹è¯
response = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹"},
        {"role": "user", "content": "è¯·è§£é‡Šä»€ä¹ˆæ˜¯é‡å­è®¡ç®—"}
    ],
    temperature=0.7
)

print(response.choices[0].message.content)
```

```javascript Node.js
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: 'YOUR_API_KEY',
  baseURL: 'https://api.laozhang.ai/v1'
});

const completion = await openai.chat.completions.create({
  model: 'gpt-4o',
  messages: [
    {role: 'system', content: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹'},
    {role: 'user', content: 'è¯·è§£é‡Šä»€ä¹ˆæ˜¯é‡å­è®¡ç®—'}
  ],
  temperature: 0.7
});

console.log(completion.choices[0].message.content);
```

</CodeGroup>

### ğŸ¯ GPT-4o å›¾åƒç†è§£

GPT-4oå¯ä»¥ç†è§£å’Œåˆ†æå›¾åƒå†…å®¹ï¼š

<CodeGroup>

```python Python
response = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼Œå¹¶åˆ†æå…¶ä¸­çš„è®¾è®¡å…ƒç´ "
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "https://example.com/image.jpg",
                        "detail": "high"  # high/low/auto
                    }
                }
            ]
        }
    ],
    max_tokens=500
)

print(response.choices[0].message.content)
```

```javascript Node.js
const completion = await openai.chat.completions.create({
  model: 'gpt-4o',
  messages: [
    {
      role: 'user',
      content: [
        {
          type: 'text',
          text: 'è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼Œå¹¶åˆ†æå…¶ä¸­çš„è®¾è®¡å…ƒç´ '
        },
        {
          type: 'image_url',
          image_url: {
            url: 'https://example.com/image.jpg',
            detail: 'high'
          }
        }
      ]
    }
  ],
  max_tokens: 500
});
```

</CodeGroup>

### âš¡ GPT-4o Mini (æ€§ä»·æ¯”ä¹‹ç‹)

**æ¨¡å‹IDï¼š** `gpt-4o-mini`

**ç‰¹ç‚¹ï¼š**
- ğŸ’° æé«˜æ€§ä»·æ¯”ï¼šè¾“å…¥ä»… $0.15/1M tokens
- ğŸš€ å“åº”é€Ÿåº¦æ›´å¿«
- ğŸ¯ ä¿æŒGPT-4oçš„æ ¸å¿ƒèƒ½åŠ›
- ğŸ’¡ é€‚åˆå¤§è§„æ¨¡åº”ç”¨

**ä»·æ ¼ï¼š** è¾“å…¥ $0.15/1M tokensï¼Œè¾“å‡º $0.6/1M tokens

```python
# GPT-4o Mini ç‰¹åˆ«é€‚åˆæ—¥å¸¸å¯¹è¯å’Œæ‰¹é‡å¤„ç†
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„å®¢æœåŠ©æ‰‹"},
        {"role": "user", "content": "æˆ‘æƒ³äº†è§£ä½ ä»¬çš„æœåŠ¡"}
    ],
    temperature=0.3
)
```

### ğŸ“… GPT-4o ç‰¹å®šç‰ˆæœ¬

**æ¨¡å‹IDï¼š** `gpt-4o-2024-11-20`

ä½¿ç”¨ç‰¹å®šæ—¥æœŸç‰ˆæœ¬ç¡®ä¿ç»“æœçš„ä¸€è‡´æ€§ï¼š

```python
response = client.chat.completions.create(
    model="gpt-4o-2024-11-20",
    messages=[
        {"role": "user", "content": "è¯·å†™ä¸€ç¯‡å…³äºAIå‘å±•çš„æ–‡ç« "}
    ],
    temperature=0.5  # è¾ƒä½æ¸©åº¦ç¡®ä¿ä¸€è‡´æ€§
)
```

## GPT-4 ç³»åˆ—

ç»å…¸çš„GPT-4ç³»åˆ—æ¨¡å‹ï¼Œæä¾›å¼ºå¤§çš„æ–‡æœ¬ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ã€‚

### ğŸ§  GPT-4 Turbo

**æ¨¡å‹IDï¼š** `gpt-4-turbo`

**ç‰¹ç‚¹ï¼š**
- ğŸš€ æ›´å¿«çš„å“åº”é€Ÿåº¦
- ğŸ“š æ”¯æŒ128Kä¸Šä¸‹æ–‡é•¿åº¦
- ğŸ’¡ ä¼˜ç§€çš„æ¨ç†èƒ½åŠ›
- ğŸ”§ é€‚åˆå¤æ‚ä»»åŠ¡

**ä»·æ ¼ï¼š** è¾“å…¥ $10/1M tokensï¼Œè¾“å‡º $30/1M tokens

```python
# å¤„ç†é•¿æ–‡æ¡£åˆ†æ
long_document = """
[è¿™é‡Œæ˜¯ä¸€ç¯‡å¾ˆé•¿çš„æ–‡æ¡£å†…å®¹...]
"""

response = client.chat.completions.create(
    model="gpt-4-turbo",
    messages=[
        {
            "role": "system", 
            "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£åˆ†æå¸ˆï¼Œè¯·ä»”ç»†åˆ†ææ–‡æ¡£å†…å®¹å¹¶æä¾›æ·±å…¥è§è§£"
        },
        {
            "role": "user", 
            "content": f"è¯·åˆ†æä»¥ä¸‹æ–‡æ¡£çš„æ ¸å¿ƒè§‚ç‚¹å’Œç»“è®ºï¼š\n\n{long_document}"
        }
    ],
    temperature=0.3
)
```

### ğŸ›ï¸ GPT-4 ç»å…¸ç‰ˆ

**æ¨¡å‹IDï¼š** `gpt-4`

ç»å…¸çš„GPT-4æ¨¡å‹ï¼Œåœ¨åˆ›æ„å†™ä½œå’Œå¤æ‚æ¨ç†æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼š

```python
# åˆ›æ„å†™ä½œä»»åŠ¡
response = client.chat.completions.create(
    model="gpt-4",
    messages=[
        {
            "role": "system", 
            "content": "ä½ æ˜¯ä¸€ä¸ªå¯Œæœ‰åˆ›æ„çš„ä½œå®¶ï¼Œæ“…é•¿åˆ›ä½œå¼•äººå…¥èƒœçš„æ•…äº‹"
        },
        {
            "role": "user", 
            "content": "è¯·å†™ä¸€ä¸ªå…³äºæ—¶é—´æ—…è¡Œçš„ç§‘å¹»çŸ­æ•…äº‹ï¼Œè¦æ±‚æœ‰æ„æƒ³ä¸åˆ°çš„ç»“å±€"
        }
    ],
    temperature=0.9,  # é«˜æ¸©åº¦å¢åŠ åˆ›æ„æ€§
    max_tokens=1000
)
```

### ğŸ“– GPT-4 32K

**æ¨¡å‹IDï¼š** `gpt-4-32k`

æ”¯æŒæ›´é•¿ä¸Šä¸‹æ–‡çš„ç‰ˆæœ¬ï¼Œé€‚åˆå¤„ç†è¶…é•¿æ–‡æ¡£ï¼š

```python
# å¤„ç†è¶…é•¿ä»£ç å®¡æŸ¥
large_codebase = """
[è¿™é‡Œæ˜¯å¤§é‡çš„ä»£ç å†…å®¹...]
"""

response = client.chat.completions.create(
    model="gpt-4-32k",
    messages=[
        {
            "role": "system", 
            "content": "ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„ä»£ç å®¡æŸ¥ä¸“å®¶"
        },
        {
            "role": "user", 
            "content": f"è¯·å®¡æŸ¥ä»¥ä¸‹ä»£ç ï¼ŒæŒ‡å‡ºæ½œåœ¨é—®é¢˜å’Œæ”¹è¿›å»ºè®®ï¼š\n\n{large_codebase}"
        }
    ],
    temperature=0.2
)
```

## O1 ç³»åˆ— (æ¨ç†ä¸“å®¶)

O1ç³»åˆ—æ˜¯OpenAIä¸“ä¸ºå¤æ‚æ¨ç†ä»»åŠ¡è®¾è®¡çš„æ¨¡å‹ï¼Œåœ¨æ•°å­¦ã€ç¼–ç¨‹ã€ç§‘å­¦ç­‰é¢†åŸŸè¡¨ç°å“è¶Šã€‚

### ğŸ“ O1 Preview

**æ¨¡å‹IDï¼š** `o1-preview`

**ç‰¹ç‚¹ï¼š**
- ğŸ§® å¼ºå¤§çš„æ•°å­¦æ¨ç†èƒ½åŠ›
- ğŸ”¬ ç§‘å­¦é—®é¢˜è§£å†³èƒ½åŠ›
- ğŸ’» å¤æ‚ç¼–ç¨‹ä»»åŠ¡
- ğŸ¯ å¤šæ­¥éª¤é€»è¾‘æ¨ç†

**ä»·æ ¼ï¼š** è¾“å…¥ $15/1M tokensï¼Œè¾“å‡º $60/1M tokens

<Warning>
  O1ç³»åˆ—æ¨¡å‹æœ‰ç‰¹æ®Šé™åˆ¶ï¼š
  - ä¸æ”¯æŒ `temperature`ã€`top_p` ç­‰å‚æ•°
  - ä¸æ”¯æŒ `system` è§’è‰²æ¶ˆæ¯
  - ä¸æ”¯æŒæµå¼è¾“å‡º
  - ä¸æ”¯æŒå‡½æ•°è°ƒç”¨
</Warning>

<CodeGroup>

```python Python
# å¤æ‚æ•°å­¦é—®é¢˜
response = client.chat.completions.create(
    model="o1-preview",
    messages=[
        {
            "role": "user",
            "content": """
            è§£å†³è¿™ä¸ªæ•°å­¦é—®é¢˜ï¼š
            
            ä¸€ä¸ªæ­£æ•´æ•°nï¼Œæ»¡è¶³ä»¥ä¸‹æ¡ä»¶ï¼š
            1. næ˜¯4ä½æ•°
            2. nçš„å„ä½æ•°å­—ä¹‹å’Œç­‰äº20
            3. næ˜¯è´¨æ•°
            4. nçš„å„ä½æ•°å­—éƒ½ä¸ç›¸åŒ
            
            è¯·æ‰¾å‡ºæ‰€æœ‰æ»¡è¶³æ¡ä»¶çš„nï¼Œå¹¶è¯´æ˜è§£é¢˜æ€è·¯ã€‚
            """
        }
    ]
)

print(response.choices[0].message.content)
```

```javascript Node.js
// å¤æ‚ç¼–ç¨‹é—®é¢˜
const completion = await openai.chat.completions.create({
  model: 'o1-preview',
  messages: [
    {
      role: 'user',
      content: `
        è¯·è®¾è®¡ä¸€ä¸ªé«˜æ•ˆçš„ç®—æ³•æ¥è§£å†³ä»¥ä¸‹é—®é¢˜ï¼š
        
        ç»™å®šä¸€ä¸ªæ•´æ•°æ•°ç»„ï¼Œæ‰¾å‡ºå…¶ä¸­å’Œä¸ºç›®æ ‡å€¼çš„ä¸‰ä¸ªæ•°çš„æ‰€æœ‰ç»„åˆï¼Œ
        è¦æ±‚æ—¶é—´å¤æ‚åº¦å°½å¯èƒ½ä½ï¼Œå¹¶æä¾›å®Œæ•´çš„ä»£ç å®ç°å’Œå¤æ‚åº¦åˆ†æã€‚
      `
    }
  ]
});
```

</CodeGroup>

### ğŸš€ O1 Mini

**æ¨¡å‹IDï¼š** `o1-mini`

è½»é‡ç‰ˆçš„æ¨ç†æ¨¡å‹ï¼Œæˆæœ¬æ›´ä½ï¼š

**ä»·æ ¼ï¼š** è¾“å…¥ $3/1M tokensï¼Œè¾“å‡º $12/1M tokens

```python
# ä¸­ç­‰å¤æ‚åº¦çš„é€»è¾‘æ¨ç†
response = client.chat.completions.create(
    model="o1-mini",
    messages=[
        {
            "role": "user",
            "content": """
            æœ‰Aã€Bã€Cã€Då››ä¸ªäººï¼Œå…¶ä¸­æœ‰ä¸€ä¸ªäººè¯´è°ï¼Œå…¶ä»–äººè¯´çœŸè¯ã€‚
            
            Aè¯´ï¼šBæ˜¯è¯´è°è€…
            Bè¯´ï¼šCæ˜¯è¯´è°è€…  
            Cè¯´ï¼šDæ˜¯è¯´è°è€…
            Dè¯´ï¼šAæ˜¯è¯´è°è€…
            
            è¯·æ¨ç†å‡ºè°æ˜¯è¯´è°è€…ï¼Œå¹¶è¯´æ˜æ¨ç†è¿‡ç¨‹ã€‚
            """
        }
    ]
)
```

### ğŸ”¬ O3 (æœ€æ–°æ¨ç†æ¨¡å‹)

**æ¨¡å‹IDï¼š** `o3`

æœ€æ–°çš„æ¨ç†æ¨¡å‹ï¼Œèƒ½åŠ›æ›´å¼ºï¼š

**ä»·æ ¼ï¼š** è¾“å…¥ $20/1M tokensï¼Œè¾“å‡º $80/1M tokens

```python
# è¶…å¤æ‚ç§‘å­¦é—®é¢˜
response = client.chat.completions.create(
    model="o3",
    messages=[
        {
            "role": "user",
            "content": """
            è¯·åˆ†æä»¥ä¸‹åŒ–å­¦ååº”çš„æœºç†ï¼Œå¹¶é¢„æµ‹åœ¨ä¸åŒæ¡ä»¶ä¸‹çš„äº§ç‰©ï¼š
            
            åœ¨å‚¬åŒ–å‰‚å­˜åœ¨ä¸‹ï¼ŒåŒ–åˆç‰©A (Câ‚ˆHâ‚â‚€Oâ‚‚) ä¸åŒ–åˆç‰©B (Câ‚„Hâ‚†Oâ‚ƒ) 
            åœ¨180Â°Cå’Œ2å¤§æ°”å‹ä¸‹ååº”ã€‚å·²çŸ¥Aå«æœ‰è‹¯ç¯å’Œé…¯åŸºï¼ŒBå«æœ‰çƒ¯çƒƒåŒé”®ã€‚
            
            è¯·æä¾›ï¼š
            1. è¯¦ç»†çš„ååº”æœºç†
            2. ä¸»è¦äº§ç‰©çš„ç»“æ„
            3. å‰¯ååº”çš„å¯èƒ½æ€§
            4. ååº”æ¡ä»¶å¯¹äº§ç‰©çš„å½±å“
            """
        }
    ]
)
```

## GPT-3.5 ç³»åˆ—

è™½ç„¶ä¸æ˜¯æœ€æ–°çš„æ¨¡å‹ï¼Œä½†GPT-3.5ç³»åˆ—ä»ç„¶æ˜¯é«˜æ€§ä»·æ¯”çš„ä¼˜ç§€é€‰æ‹©ã€‚

### âš¡ GPT-3.5 Turbo

**æ¨¡å‹IDï¼š** `gpt-3.5-turbo`

**ç‰¹ç‚¹ï¼š**
- ğŸ’° æé«˜æ€§ä»·æ¯”
- ğŸš€ å“åº”é€Ÿåº¦å¿«
- ğŸ“± é€‚åˆç§»åŠ¨åº”ç”¨
- ğŸ”„ é€‚åˆé«˜é¢‘è°ƒç”¨

**ä»·æ ¼ï¼š** è¾“å…¥ $0.5/1M tokensï¼Œè¾“å‡º $1.5/1M tokens

```python
# é«˜é¢‘ç®€å•ä»»åŠ¡ï¼Œå¦‚ç¿»è¯‘ã€æ‘˜è¦ç­‰
response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {
            "role": "system", 
            "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘ä¸“å®¶"
        },
        {
            "role": "user", 
            "content": "è¯·å°†ä»¥ä¸‹è‹±æ–‡ç¿»è¯‘æˆä¸­æ–‡ï¼š'The future of artificial intelligence looks promising.'"
        }
    ],
    temperature=0.3
)
```

## ä½¿ç”¨æŠ€å·§å’Œæœ€ä½³å®è·µ

### 1. é€‰æ‹©åˆé€‚çš„æ¨¡å‹

<AccordionGroup>
  <Accordion icon="lightbulb" title="æ—¥å¸¸å¯¹è¯èŠå¤©">
    **æ¨èï¼š** GPT-4o Mini, GPT-3.5 Turbo
    
    ```python
    # ç®€å•å¯¹è¯ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹
    model = "gpt-4o-mini"  # æ€§ä»·æ¯”æœ€ä½³
    temperature = 0.7      # è‡ªç„¶å¯¹è¯
    ```
  </Accordion>

  <Accordion icon="code" title="ä»£ç ç¼–ç¨‹ä»»åŠ¡">
    **æ¨èï¼š** GPT-4o, GPT-4 Turbo
    
    ```python
    # ä»£ç ç”Ÿæˆå’Œè°ƒè¯•
    model = "gpt-4o"       # æœ€æ–°ä»£ç èƒ½åŠ›
    temperature = 0.2      # ç²¾ç¡®æ€§ä¼˜å…ˆ
    max_tokens = 2000      # è¶³å¤Ÿé•¿çš„ä»£ç 
    ```
  </Accordion>

  <Accordion icon="brain" title="å¤æ‚æ¨ç†åˆ†æ">
    **æ¨èï¼š** O1 Preview, O1 Mini
    
    ```python
    # æ•°å­¦ã€é€»è¾‘ã€ç§‘å­¦é—®é¢˜
    model = "o1-preview"   # æœ€å¼ºæ¨ç†èƒ½åŠ›
    # æ³¨æ„ï¼šO1ç³»åˆ—ä¸æ”¯æŒtemperatureç­‰å‚æ•°
    ```
  </Accordion>

  <Accordion icon="image" title="å›¾åƒç†è§£ä»»åŠ¡">
    **æ¨èï¼š** GPT-4o, GPT-4o Mini
    
    ```python
    # å›¾åƒåˆ†æå’Œç†è§£
    model = "gpt-4o"       # æœ€ä½³è§†è§‰èƒ½åŠ›
    detail = "high"        # é«˜æ¸…æ™°åº¦åˆ†æ
    ```
  </Accordion>
</AccordionGroup>

### 2. ä¼˜åŒ–æç¤ºè¯

<CodeGroup>

```python ç³»ç»Ÿæ¶ˆæ¯è®¾è®¡
# å¥½çš„ç³»ç»Ÿæ¶ˆæ¯ç¤ºä¾‹
system_prompt = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Pythonç¼–ç¨‹ä¸“å®¶ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š
1. ä»£ç é£æ ¼éµå¾ªPEP8è§„èŒƒ
2. æ³¨é‡ä»£ç å¯è¯»æ€§å’Œæ€§èƒ½
3. æä¾›è¯¦ç»†çš„æ³¨é‡Šå’Œè¯´æ˜
4. ç»™å‡ºå¤šç§è§£å†³æ–¹æ¡ˆå¯¹æ¯”

è¯·ç”¨ç®€æ´æ˜äº†çš„è¯­è¨€å›ç­”ï¼Œå¹¶æä¾›å¯æ‰§è¡Œçš„ä»£ç ç¤ºä¾‹ã€‚
"""
```

```python ç»“æ„åŒ–æç¤º
# ç»“æ„åŒ–ä»»åŠ¡æç¤º
user_prompt = """
è¯·å¸®æˆ‘åˆ†æä»¥ä¸‹ä»£ç çš„æ€§èƒ½ç“¶é¢ˆï¼š

## ä»£ç ï¼š
[ä»£ç å†…å®¹]

## åˆ†æè¦æ±‚ï¼š
1. è¯†åˆ«æ€§èƒ½ç“¶é¢ˆç‚¹
2. æä¾›ä¼˜åŒ–å»ºè®®
3. ç»™å‡ºä¼˜åŒ–åçš„ä»£ç 
4. æ¯”è¾ƒä¼˜åŒ–å‰åçš„æ—¶é—´å¤æ‚åº¦

è¯·æŒ‰ç…§ä¸Šè¿°ç»“æ„å›ç­”ã€‚
"""
```

</CodeGroup>

### 3. å‚æ•°è°ƒä¼˜

<AccordionGroup>
  <Accordion icon="thermometer" title="Temperature è®¾ç½®">
    - **0.0-0.3**: éœ€è¦ç²¾ç¡®ã€ä¸€è‡´çš„è¾“å‡ºï¼ˆä»£ç ã€æ•°æ®åˆ†æï¼‰
    - **0.4-0.7**: å¹³è¡¡åˆ›é€ æ€§å’Œå‡†ç¡®æ€§ï¼ˆæ—¥å¸¸å¯¹è¯ï¼‰
    - **0.8-1.0**: éœ€è¦åˆ›é€ æ€§å’Œå¤šæ ·æ€§ï¼ˆåˆ›æ„å†™ä½œï¼‰
    
    ```python
    # ä¸åŒä»»åŠ¡çš„æ¸©åº¦è®¾ç½®
    code_generation = {"temperature": 0.2}
    casual_chat = {"temperature": 0.7}
    creative_writing = {"temperature": 0.9}
    ```
  </Accordion>

  <Accordion icon="scissors" title="Max Tokens æ§åˆ¶">
    æ ¹æ®ä»»åŠ¡ç±»å‹è®¾ç½®åˆé€‚çš„è¾“å‡ºé•¿åº¦ï¼š
    
    ```python
    token_limits = {
        "ç®€çŸ­å›ç­”": 100,
        "è¯¦ç»†è§£é‡Š": 500,
        "ä»£ç ç”Ÿæˆ": 2000,
        "é•¿æ–‡æ¡£": 4000
    }
    ```
  </Accordion>

  <Accordion icon="stop-circle" title="Stop åºåˆ—">
    ä½¿ç”¨åœæ­¢åºåˆ—æ§åˆ¶è¾“å‡ºæ ¼å¼ï¼š
    
    ```python
    # ç”Ÿæˆåˆ—è¡¨æ—¶çš„åœæ­¢åºåˆ—
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[...],
        stop=["6.", "\n\n", "æ€»ç»“ï¼š"]
    )
    ```
  </Accordion>
</AccordionGroup>

### 4. æˆæœ¬ä¼˜åŒ–ç­–ç•¥

<CardGroup cols={2}>
  <Card
    title="æ¸è¿›å¼æ¨¡å‹é€‰æ‹©"
    icon="arrow-up"
  >
    å…ˆç”¨ä¾¿å®œæ¨¡å‹æµ‹è¯•ï¼Œå†ç”¨é«˜çº§æ¨¡å‹ä¼˜åŒ–
    
    ```python
    # å…ˆç”¨GPT-4o Miniæµ‹è¯•
    # å†ç”¨GPT-4oå®Œå–„
    ```
  </Card>

  <Card
    title="æ™ºèƒ½ç¼“å­˜"
    icon="database"
  >
    å¯¹é‡å¤è¯·æ±‚è¿›è¡Œç¼“å­˜ï¼Œé¿å…é‡å¤è®¡è´¹
    
    ```python
    import hashlib
    cache = {}
    
    def cached_completion(prompt):
        key = hashlib.md5(prompt.encode()).hexdigest()
        if key in cache:
            return cache[key]
        # è°ƒç”¨API...
    ```
  </Card>

  <Card
    title="æ‰¹é‡å¤„ç†"
    icon="layer-group"
  >
    å°†å¤šä¸ªç®€å•ä»»åŠ¡åˆå¹¶ä¸ºä¸€ä¸ªè¯·æ±‚
    
    ```python
    # åˆå¹¶å¤šä¸ªç¿»è¯‘ä»»åŠ¡
    batch_prompt = """
    è¯·ç¿»è¯‘ä»¥ä¸‹å¥å­ï¼š
    1. Hello world
    2. Good morning
    3. Thank you
    """
    ```
  </Card>

  <Card
    title="ç²¾ç¡®æ§åˆ¶é•¿åº¦"
    icon="ruler"
  >
    è®¾ç½®åˆé€‚çš„max_tokensé¿å…æµªè´¹
    
    ```python
    # æ ¹æ®ä»»åŠ¡è®¾ç½®ç²¾ç¡®çš„tokené™åˆ¶
    max_tokens = estimate_needed_tokens(task_type)
    ```
  </Card>
</CardGroup>

## é”™è¯¯å¤„ç†å’Œé‡è¯•

```python
import time
import random
from openai import OpenAI

def robust_completion(client, **kwargs):
    """å¸¦é‡è¯•æœºåˆ¶çš„APIè°ƒç”¨"""
    max_retries = 3
    base_delay = 1
    
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(**kwargs)
            return response
        
        except Exception as e:
            if attempt == max_retries - 1:
                raise e
                
            # æŒ‡æ•°é€€é¿é‡è¯•
            delay = base_delay * (2 ** attempt) + random.uniform(0, 1)
            print(f"é‡è¯• {attempt + 1}/{max_retries}ï¼Œç­‰å¾… {delay:.2f} ç§’...")
            time.sleep(delay)

# ä½¿ç”¨ç¤ºä¾‹
try:
    response = robust_completion(
        client,
        model="gpt-4o",
        messages=[{"role": "user", "content": "Hello!"}]
    )
except Exception as e:
    print(f"APIè°ƒç”¨å¤±è´¥: {e}")
```

## æµå¼å“åº”å¤„ç†

å¯¹äºé•¿æ–‡æœ¬ç”Ÿæˆï¼Œå»ºè®®ä½¿ç”¨æµå¼å“åº”æå‡ç”¨æˆ·ä½“éªŒï¼š

```python
def stream_completion(client, **kwargs):
    """æµå¼å“åº”å¤„ç†"""
    kwargs['stream'] = True
    
    try:
        stream = client.chat.completions.create(**kwargs)
        
        for chunk in stream:
            if chunk.choices[0].delta.content is not None:
                content = chunk.choices[0].delta.content
                print(content, end='', flush=True)
                yield content
                
    except Exception as e:
        print(f"æµå¼å“åº”é”™è¯¯: {e}")

# ä½¿ç”¨ç¤ºä¾‹
for chunk in stream_completion(
    client,
    model="gpt-4o",
    messages=[{"role": "user", "content": "å†™ä¸€ç¯‡å…³äºAIçš„æ–‡ç« "}]
):
    # å®æ—¶å¤„ç†æ¯ä¸ªæ–‡æœ¬å—
    pass
```

---

<CardGroup cols={2}>
  <Card
    title="æ¢ç´¢Claudeæ¨¡å‹"
    icon="anthropic"
    href="/api-reference/claude"
  >
    äº†è§£Claudeç³»åˆ—æ¨¡å‹çš„ç‹¬ç‰¹ä¼˜åŠ¿å’Œä½¿ç”¨æ–¹æ³•
  </Card>
  <Card
    title="æŸ¥çœ‹å®Œæ•´æ¨¡å‹åˆ—è¡¨"
    icon="list"
    href="/models"
  >
    æµè§ˆè€å¼ APIæ”¯æŒçš„æ‰€æœ‰200+AIæ¨¡å‹
  </Card>
</CardGroup> 