---
title: 'Claudeæ¨¡å‹ä½¿ç”¨æŒ‡å—'
description: 'Anthropic Claudeç³»åˆ—æ¨¡å‹çš„è¯¦ç»†ä½¿ç”¨æŒ‡å—'
---

# Claudeæ¨¡å‹ä½¿ç”¨æŒ‡å—

Claudeæ˜¯ç”±Anthropicå¼€å‘çš„å…ˆè¿›AIåŠ©æ‰‹ï¼Œä»¥å…¶å‡ºè‰²çš„æ¨ç†èƒ½åŠ›ã€å®‰å…¨æ€§å’Œæœ‰ç”¨æ€§è€Œé—»åã€‚åœ¨APIæ˜“å¹³å°ä¸Šï¼Œä½ å¯ä»¥ä½¿ç”¨Claudeçš„æœ€æ–°æ¨¡å‹ï¼ŒåŒ…æ‹¬Claude 3.5 Sonnetã€Claude 3 Opusç­‰ã€‚

## ğŸš€ æ¨¡å‹æ¦‚è§ˆ

<CardGroup cols={2}>
  <Card
    title="Claude 3.5 Sonnet"
    icon="anthropic"
    href="#claude-3-5-sonnet"
  >
    æœ€æ–°æ——èˆ°æ¨¡å‹ï¼Œæ™ºèƒ½ä¸é€Ÿåº¦çš„å®Œç¾å¹³è¡¡
  </Card>
  <Card
    title="Claude 3 Opus"
    icon="crown"
    href="#claude-3-opus"
  >
    æœ€å¼ºå¤§çš„æ¨¡å‹ï¼Œé€‚åˆå¤æ‚ä»»åŠ¡
  </Card>
  <Card
    title="Claude 3 Sonnet"
    icon="balance-scale"
    href="#claude-3-sonnet"
  >
    å¹³è¡¡æ€§èƒ½ä¸æˆæœ¬çš„ç»å…¸é€‰æ‹©
  </Card>
  <Card
    title="Claude 3 Haiku"
    icon="feather"
    href="#claude-3-haiku"
  >
    è½»é‡å¿«é€Ÿï¼Œé€‚åˆç®€å•ä»»åŠ¡
  </Card>
</CardGroup>

## Claude 3.5 Sonnet (æ¨è)

Claude 3.5 Sonnetæ˜¯Anthropicçš„æœ€æ–°æ——èˆ°æ¨¡å‹ï¼Œåœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶æ˜¾è‘—æå‡äº†å¤„ç†é€Ÿåº¦ã€‚

### ğŸ¯ æ ¸å¿ƒç‰¹æ€§

**æ¨¡å‹IDï¼š** `claude-3-5-sonnet-20241022`

**ç‰¹ç‚¹ï¼š**
- ğŸ§  å“è¶Šçš„æ¨ç†å’Œåˆ†æèƒ½åŠ›
- ğŸ“ ä¼˜ç§€çš„é•¿æ–‡æœ¬å¤„ç†èƒ½åŠ›
- ğŸ” ç²¾å‡†çš„ä¿¡æ¯æå–å’Œæ€»ç»“
- ğŸ¨ å¼ºå¤§çš„åˆ›æ„å†™ä½œèƒ½åŠ›
- ğŸŒ ä¼˜ç§€çš„ä¸­æ–‡ç†è§£å’Œç”Ÿæˆ
- ğŸ”’ å†…ç½®å®‰å…¨æœºåˆ¶ï¼Œæ‹’ç»æœ‰å®³å†…å®¹

**ä»·æ ¼ï¼š** è¾“å…¥ $3/1M tokensï¼Œè¾“å‡º $15/1M tokens

<CodeGroup>

```python Python
from openai import OpenAI

client = OpenAI(
    api_key="YOUR_API_KEY",
    base_url="https://api.apiyi.com/v1"
)

# åŸºç¡€å¯¹è¯
response = client.chat.completions.create(
    model="claude-3-5-sonnet-20241022",
    messages=[
        {
            "role": "system", 
            "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æå’Œè§£å†³å¤æ‚é—®é¢˜"
        },
        {
            "role": "user", 
            "content": "è¯·åˆ†æä¸€ä¸‹å½“å‰äººå·¥æ™ºèƒ½å‘å±•çš„ä¸»è¦è¶‹åŠ¿å’ŒæŒ‘æˆ˜"
        }
    ],
    max_tokens=1000,
    temperature=0.7
)

print(response.choices[0].message.content)
```

```javascript Node.js
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: 'YOUR_API_KEY',
  baseURL: 'https://api.apiyi.com/v1'
});

const completion = await openai.chat.completions.create({
  model: 'claude-3-5-sonnet-20241022',
  messages: [
    {
      role: 'system',
      content: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æå’Œè§£å†³å¤æ‚é—®é¢˜'
    },
    {
      role: 'user',
      content: 'è¯·åˆ†æä¸€ä¸‹å½“å‰äººå·¥æ™ºèƒ½å‘å±•çš„ä¸»è¦è¶‹åŠ¿å’ŒæŒ‘æˆ˜'
    }
  ],
  max_tokens: 1000,
  temperature: 0.7
});

console.log(completion.choices[0].message.content);
```

```go Go
package main

import (
    "context"
    "fmt"
    "log"
    
    "github.com/sashabaranov/go-openai"
)

func main() {
    config := openai.DefaultConfig("YOUR_API_KEY")
    config.BaseURL = "https://api.apiyi.com/v1"
    client := openai.NewClientWithConfig(config)
    
    resp, err := client.CreateChatCompletion(
        context.Background(),
        openai.ChatCompletionRequest{
            Model: "claude-3-5-sonnet-20241022",
            Messages: []openai.ChatCompletionMessage{
                {
                    Role:    openai.ChatMessageRoleSystem,
                    Content: "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æå’Œè§£å†³å¤æ‚é—®é¢˜",
                },
                {
                    Role:    openai.ChatMessageRoleUser,
                    Content: "è¯·åˆ†æä¸€ä¸‹å½“å‰äººå·¥æ™ºèƒ½å‘å±•çš„ä¸»è¦è¶‹åŠ¿å’ŒæŒ‘æˆ˜",
                },
            },
            MaxTokens:   1000,
            Temperature: 0.7,
        },
    )
    
    if err != nil {
        log.Fatal(err)
    }
    
    fmt.Println(resp.Choices[0].Message.Content)
}
```

```bash cURL
curl -X POST "https://api.apiyi.com/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "model": "claude-3-5-sonnet-20241022",
    "messages": [
      {
        "role": "system",
        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æå’Œè§£å†³å¤æ‚é—®é¢˜"
      },
      {
        "role": "user",
        "content": "è¯·åˆ†æä¸€ä¸‹å½“å‰äººå·¥æ™ºèƒ½å‘å±•çš„ä¸»è¦è¶‹åŠ¿å’ŒæŒ‘æˆ˜"
      }
    ],
    "max_tokens": 1000,
    "temperature": 0.7
  }'
```

</CodeGroup>

### ğŸ¨ åˆ›æ„å†™ä½œç¤ºä¾‹

Claude 3.5 Sonnetåœ¨åˆ›æ„å†™ä½œæ–¹é¢è¡¨ç°å‡ºè‰²ï¼š

```python
# åˆ›æ„å†™ä½œä»»åŠ¡
response = client.chat.completions.create(
    model="claude-3-5-sonnet-20241022",
    messages=[
        {
            "role": "system", 
            "content": "ä½ æ˜¯ä¸€ä¸ªæ‰åæ¨ªæº¢çš„ä½œå®¶ï¼Œæ“…é•¿åˆ›ä½œå¼•äººå…¥èƒœçš„æ•…äº‹"
        },
        {
            "role": "user", 
            "content": """
            è¯·å†™ä¸€ä¸ªå…³äº"æ—¶é—´æ—…è¡Œè€…çš„å›°å¢ƒ"çš„çŸ­æ•…äº‹ï¼Œè¦æ±‚ï¼š
            1. æ•…äº‹é•¿åº¦çº¦800å­—
            2. åŒ…å«æ„æƒ³ä¸åˆ°çš„è½¬æŠ˜
            3. æ¢è®¨æ—¶é—´æ—…è¡Œçš„å“²å­¦é—®é¢˜
            4. ç»“å°¾è¦æœ‰æ·±åˆ»çš„å¯ç¤º
            """
        }
    ],
    max_tokens=1500,
    temperature=0.8  # è¾ƒé«˜æ¸©åº¦å¢åŠ åˆ›é€ æ€§
)

print(response.choices[0].message.content)
```

### ğŸ“Š æ•°æ®åˆ†æç¤ºä¾‹

```python
# å¤æ‚æ•°æ®åˆ†æä»»åŠ¡
data_analysis_prompt = """
ä»¥ä¸‹æ˜¯æŸç”µå•†ç½‘ç«™çš„ç”¨æˆ·è¡Œä¸ºæ•°æ®æ‘˜è¦ï¼š
- æ—¥å‡è®¿é—®é‡ï¼š50,000
- é¡µé¢è·³å‡ºç‡ï¼š35%
- å¹³å‡åœç•™æ—¶é—´ï¼š3.2åˆ†é’Ÿ
- è½¬åŒ–ç‡ï¼š2.8%
- ç§»åŠ¨ç«¯å æ¯”ï¼š65%
- ä¸»è¦æµé‡æ¥æºï¼šæœç´¢å¼•æ“(45%)ã€ç¤¾äº¤åª’ä½“(25%)ã€ç›´æ¥è®¿é—®(20%)ã€å…¶ä»–(10%)

è¯·è¿›è¡Œæ·±å…¥åˆ†æï¼Œæä¾›ï¼š
1. ç°çŠ¶è¯„ä¼°
2. ä¸»è¦é—®é¢˜è¯†åˆ«
3. ä¼˜åŒ–å»ºè®®
4. é¢„æœŸæ”¹å–„æ•ˆæœ
"""

response = client.chat.completions.create(
    model="claude-3-5-sonnet-20241022",
    messages=[
        {
            "role": "system", 
            "content": "ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„æ•°æ®åˆ†æå¸ˆå’Œå¢é•¿ä¸“å®¶ï¼Œæ“…é•¿ç”µå•†æ•°æ®åˆ†æ"
        },
        {
            "role": "user", 
            "content": data_analysis_prompt
        }
    ],
    max_tokens=2000,
    temperature=0.3  # ä½æ¸©åº¦ä¿è¯åˆ†æçš„å‡†ç¡®æ€§
)
```

## Claude 3 Opus (æœ€å¼ºå¤§)

Claude 3 Opusæ˜¯Anthropicæœ€å¼ºå¤§çš„æ¨¡å‹ï¼Œåœ¨å¤æ‚æ¨ç†ã€åˆ›æ„ä»»åŠ¡å’Œé•¿æ–‡æœ¬å¤„ç†æ–¹é¢è¡¨ç°å“è¶Šã€‚

### ğŸ‘‘ æ ¸å¿ƒç‰¹æ€§

**æ¨¡å‹IDï¼š** `claude-3-opus-20240229`

**ç‰¹ç‚¹ï¼š**
- ğŸ† æœ€å¼ºçš„æ¨ç†å’Œåˆ†æèƒ½åŠ›
- ğŸ“š å“è¶Šçš„é•¿æ–‡æ¡£å¤„ç†èƒ½åŠ›
- ğŸ¯ ç²¾å‡†çš„å¤æ‚ä»»åŠ¡æ‰§è¡Œ
- ğŸ”¬ æ·±åº¦çš„ç§‘å­¦å’ŒæŠ€æœ¯åˆ†æ
- ğŸ’¡ ä¼˜ç§€çš„åˆ›æ„å’Œæƒ³è±¡åŠ›

**ä»·æ ¼ï¼š** è¾“å…¥ $15/1M tokensï¼Œè¾“å‡º $75/1M tokens

### ğŸ”¬ ç§‘å­¦åˆ†æç¤ºä¾‹

```python
# å¤æ‚ç§‘å­¦é—®é¢˜åˆ†æ
scientific_query = """
è¯·åˆ†æCRISPR-Cas9åŸºå› ç¼–è¾‘æŠ€æœ¯çš„æœ€æ–°å‘å±•ï¼ŒåŒ…æ‹¬ï¼š

1. æŠ€æœ¯åŸç†å’Œæœºåˆ¶
2. æœ€æ–°çš„æ”¹è¿›å’Œå˜ç§ï¼ˆå¦‚Prime Editingã€Base Editingï¼‰
3. åœ¨åŒ»å­¦æ²»ç–—ä¸­çš„åº”ç”¨ç°çŠ¶
4. ä¼¦ç†å’Œå®‰å…¨æ€§é—®é¢˜
5. æœªæ¥å‘å±•è¶‹åŠ¿å’ŒæŒ‘æˆ˜

è¯·æä¾›è¯¦ç»†çš„ç§‘å­¦åˆ†æï¼ŒåŒ…æ‹¬å…·ä½“çš„ç ”ç©¶æ¡ˆä¾‹å’Œæ•°æ®ã€‚
"""

response = client.chat.completions.create(
    model="claude-3-opus-20240229",
    messages=[
        {
            "role": "system", 
            "content": "ä½ æ˜¯ä¸€ä¸ªé¡¶å°–çš„ç”Ÿç‰©æŠ€æœ¯ä¸“å®¶ï¼Œå…·æœ‰æ·±åšçš„åˆ†å­ç”Ÿç‰©å­¦å’ŒåŸºå› å·¥ç¨‹èƒŒæ™¯"
        },
        {
            "role": "user", 
            "content": scientific_query
        }
    ],
    max_tokens=3000,
    temperature=0.2
)
```

### ğŸ“– é•¿æ–‡æ¡£å¤„ç†ç¤ºä¾‹

```python
# é•¿æ–‡æ¡£æ€»ç»“å’Œåˆ†æ
long_document = """
[è¿™é‡Œæ˜¯ä¸€ä»½å¾ˆé•¿çš„æŠ€æœ¯æ–‡æ¡£æˆ–å­¦æœ¯è®ºæ–‡...]
"""

response = client.chat.completions.create(
    model="claude-3-opus-20240229",
    messages=[
        {
            "role": "system", 
            "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£åˆ†æå¸ˆï¼Œæ“…é•¿æå–å…³é”®ä¿¡æ¯å’Œæ·±å…¥åˆ†æ"
        },
        {
            "role": "user", 
            "content": f"""
            è¯·å¯¹ä»¥ä¸‹æ–‡æ¡£è¿›è¡Œæ·±å…¥åˆ†æï¼š
            
            {long_document}
            
            è¯·æä¾›ï¼š
            1. æ‰§è¡Œæ‘˜è¦ï¼ˆ300å­—ä»¥å†…ï¼‰
            2. å…³é”®å‘ç°å’Œç»“è®º
            3. æ–¹æ³•è®ºè¯„ä¼°
            4. æ½œåœ¨åº”ç”¨ä»·å€¼
            5. æœªæ¥ç ”ç©¶æ–¹å‘å»ºè®®
            """
        }
    ],
    max_tokens=2500,
    temperature=0.3
)
```

## Claude 3 Sonnet (å¹³è¡¡é€‰æ‹©)

Claude 3 Sonnetåœ¨æ€§èƒ½å’Œæˆæœ¬ä¹‹é—´æä¾›äº†æœ€ä½³å¹³è¡¡ï¼Œé€‚åˆå¤§å¤šæ•°åº”ç”¨åœºæ™¯ã€‚

### âš–ï¸ æ ¸å¿ƒç‰¹æ€§

**æ¨¡å‹IDï¼š** `claude-3-sonnet-20240229`

**ç‰¹ç‚¹ï¼š**
- ğŸ¯ å¹³è¡¡çš„æ€§èƒ½å’Œæˆæœ¬
- ğŸš€ è¾ƒå¿«çš„å“åº”é€Ÿåº¦
- ğŸ“ è‰¯å¥½çš„æ–‡æœ¬ç”Ÿæˆè´¨é‡
- ğŸ’¼ é€‚åˆå•†ä¸šåº”ç”¨

**ä»·æ ¼ï¼š** è¾“å…¥ $3/1M tokensï¼Œè¾“å‡º $15/1M tokens

### ğŸ’¼ å•†ä¸šåº”ç”¨ç¤ºä¾‹

```python
# å•†ä¸šåˆ†æä»»åŠ¡
business_analysis = """
æŸç§‘æŠ€å…¬å¸è®¡åˆ’è¿›å…¥AIèŠå¤©æœºå™¨äººå¸‚åœºï¼Œé¢ä¸´çš„æƒ…å†µï¼š
- å¸‚åœºç°çŠ¶ï¼šå·²æœ‰OpenAIã€Googleã€Microsoftç­‰å·¨å¤´
- å…¬å¸ä¼˜åŠ¿ï¼šåœ¨å‚ç›´é¢†åŸŸæœ‰æ·±åšæŠ€æœ¯ç§¯ç´¯
- èµ„æºé™åˆ¶ï¼šç ”å‘é¢„ç®—æœ‰é™ï¼Œå›¢é˜Ÿè§„æ¨¡ä¸­ç­‰
- ç›®æ ‡å¸‚åœºï¼šä¼ä¸šçº§å®¢æˆ·

è¯·æä¾›è¯¦ç»†çš„å¸‚åœºè¿›å…¥ç­–ç•¥åˆ†æã€‚
"""

response = client.chat.completions.create(
    model="claude-3-sonnet-20240229",
    messages=[
        {
            "role": "system", 
            "content": "ä½ æ˜¯ä¸€ä¸ªç»éªŒä¸°å¯Œçš„å•†ä¸šç­–ç•¥é¡¾é—®ï¼Œæ“…é•¿ç§‘æŠ€è¡Œä¸šåˆ†æ"
        },
        {
            "role": "user", 
            "content": business_analysis
        }
    ],
    max_tokens=2000,
    temperature=0.4
)
```

### ğŸ“š æ•™è‚²å†…å®¹ç”Ÿæˆ

```python
# æ•™è‚²å†…å®¹åˆ›ä½œ
response = client.chat.completions.create(
    model="claude-3-sonnet-20240229",
    messages=[
        {
            "role": "system", 
            "content": "ä½ æ˜¯ä¸€ä¸ªä¼˜ç§€çš„æ•™è‚²å†…å®¹åˆ›ä½œè€…ï¼Œæ“…é•¿è®¾è®¡å¼•äººå…¥èƒœçš„å­¦ä¹ ææ–™"
        },
        {
            "role": "user", 
            "content": """
            è¯·ä¸ºé«˜ä¸­ç”Ÿè®¾è®¡ä¸€ä¸ªå…³äº"é‡å­è®¡ç®—åŸºç¡€"çš„æ•™å­¦æ¨¡å—ï¼ŒåŒ…æ‹¬ï¼š
            1. å­¦ä¹ ç›®æ ‡
            2. æ ¸å¿ƒæ¦‚å¿µè§£é‡Šï¼ˆç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€ï¼‰
            3. å®é™…åº”ç”¨ä¾‹å­
            4. äº’åŠ¨ç»ƒä¹ é¢˜
            5. æ‹“å±•é˜…è¯»å»ºè®®
            """
        }
    ],
    max_tokens=2000,
    temperature=0.6
)
```

## Claude 3 Haiku (è½»é‡å¿«é€Ÿ)

Claude 3 Haikuæ˜¯Claudeç³»åˆ—ä¸­æœ€è½»é‡çš„æ¨¡å‹ï¼Œæä¾›å¿«é€Ÿå“åº”å’Œæé«˜çš„æ€§ä»·æ¯”ã€‚

### ğŸª¶ æ ¸å¿ƒç‰¹æ€§

**æ¨¡å‹IDï¼š** `claude-3-haiku-20240307`

**ç‰¹ç‚¹ï¼š**
- âš¡ æå¿«çš„å“åº”é€Ÿåº¦
- ğŸ’° è¶…é«˜æ€§ä»·æ¯”
- ğŸ¯ é€‚åˆç®€å•ä»»åŠ¡
- ğŸ“± ç§»åŠ¨åº”ç”¨å‹å¥½

**ä»·æ ¼ï¼š** è¾“å…¥ $0.25/1M tokensï¼Œè¾“å‡º $1.25/1M tokens

### ğŸš€ å¿«é€Ÿä»»åŠ¡ç¤ºä¾‹

```python
# å¿«é€Ÿæ–‡æœ¬å¤„ç†ä»»åŠ¡
tasks = [
    "å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘æˆè‹±æ–‡ï¼šäººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œ",
    "æ€»ç»“è¿™æ®µè¯çš„è¦ç‚¹ï¼š[ä¸€æ®µæ–‡æœ¬]",
    "ç”Ÿæˆ5ä¸ªå…³äºç¯ä¿çš„æ ‡è¯­",
    "æ£€æŸ¥è¿™å¥è¯çš„è¯­æ³•ï¼šMe and my friend goes to school"
]

for task in tasks:
    response = client.chat.completions.create(
        model="claude-3-haiku-20240307",
        messages=[
            {
                "role": "user", 
                "content": task
            }
        ],
        max_tokens=200,
        temperature=0.5
    )
    print(f"ä»»åŠ¡: {task}")
    print(f"ç»“æœ: {response.choices[0].message.content}\n")
```

### ğŸ“± ç§»åŠ¨åº”ç”¨é›†æˆ

```python
# é€‚åˆç§»åŠ¨åº”ç”¨çš„è½»é‡çº§å¯¹è¯
def mobile_chat_handler(user_message):
    """ç§»åŠ¨åº”ç”¨ä¸­çš„å¿«é€Ÿå¯¹è¯å¤„ç†"""
    response = client.chat.completions.create(
        model="claude-3-haiku-20240307",
        messages=[
            {
                "role": "system", 
                "content": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„ç§»åŠ¨åŠ©æ‰‹ï¼Œå›ç­”è¦ç®€æ´æ˜äº†"
            },
            {
                "role": "user", 
                "content": user_message
            }
        ],
        max_tokens=150,  # é™åˆ¶è¾“å‡ºé•¿åº¦
        temperature=0.7
    )
    
    return response.choices[0].message.content

# ç¤ºä¾‹ä½¿ç”¨
user_inputs = [
    "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
    "æ¨èä¸€ä¸ªå¥½çš„é¤å…",
    "å¸®æˆ‘è®¾ä¸ª5åˆ†é’Ÿçš„æé†’"
]

for input_text in user_inputs:
    response = mobile_chat_handler(input_text)
    print(f"ç”¨æˆ·: {input_text}")
    print(f"åŠ©æ‰‹: {response}\n")
```

## Claudeæ¨¡å‹çš„ç‹¬ç‰¹ä¼˜åŠ¿

### 1. ğŸ”’ å†…ç½®å®‰å…¨æœºåˆ¶

Claudeæ¨¡å‹å…·æœ‰å¼ºå¤§çš„å†…ç½®å®‰å…¨æœºåˆ¶ï¼Œä¼šä¸»åŠ¨æ‹’ç»æœ‰å®³ã€è¿æ³•æˆ–ä¸å½“çš„è¯·æ±‚ï¼š

```python
# Claudeä¼šè‡ªåŠ¨æ‹’ç»æœ‰å®³å†…å®¹
response = client.chat.completions.create(
    model="claude-3-5-sonnet-20241022",
    messages=[
        {
            "role": "user", 
            "content": "è¯·æ•™æˆ‘å¦‚ä½•åˆ¶ä½œå±é™©ç‰©å“"
        }
    ],
    max_tokens=500
)

# Claudeä¼šç¤¼è²Œåœ°æ‹’ç»å¹¶æä¾›æ›¿ä»£å»ºè®®
print(response.choices[0].message.content)
```

### 2. ğŸ¯ ç²¾å‡†çš„æŒ‡ä»¤éµå¾ª

Claudeåœ¨éµå¾ªå¤æ‚æŒ‡ä»¤æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·çš„è¦æ±‚æ‰§è¡Œä»»åŠ¡ï¼š

```python
# å¤æ‚çš„æ ¼å¼åŒ–è¦æ±‚
structured_task = """
è¯·åˆ†æä»¥ä¸‹äº§å“æ•°æ®ï¼Œå¹¶ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

æ ¼å¼è¦æ±‚ï¼š
1. ä½¿ç”¨JSONæ ¼å¼
2. åŒ…å«äº§å“åç§°ã€ä»·æ ¼ã€è¯„åˆ†ã€æ¨èç†ç”±
3. æ¨èç†ç”±ä¸è¶…è¿‡50å­—
4. æŒ‰è¯„åˆ†ä»é«˜åˆ°ä½æ’åº

äº§å“æ•°æ®ï¼š
- iPhone 15: $999, è¯„åˆ†4.5
- Samsung Galaxy S24: $899, è¯„åˆ†4.3
- Google Pixel 8: $699, è¯„åˆ†4.4

è¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–å†…å®¹ã€‚
"""

response = client.chat.completions.create(
    model="claude-3-5-sonnet-20241022",
    messages=[
        {
            "role": "user", 
            "content": structured_task
        }
    ],
    max_tokens=500,
    temperature=0.1  # ä½æ¸©åº¦ç¡®ä¿ç²¾ç¡®éµå¾ªæ ¼å¼
)
```

### 3. ğŸ§  æ·±åº¦æ¨ç†èƒ½åŠ›

Claudeåœ¨é€»è¾‘æ¨ç†å’Œæ‰¹åˆ¤æ€§æ€è€ƒæ–¹é¢è¡¨ç°å“è¶Šï¼š

```python
# å¤æ‚é€»è¾‘æ¨ç†
logical_puzzle = """
æœ‰ä¸€ä¸ªé€»è¾‘è°œé¢˜ï¼š

å°é•‡ä¸Šæœ‰ä¸‰ä¸ªäººï¼šAã€Bã€C
- Aæ€»æ˜¯è¯´çœŸè¯
- Bæ€»æ˜¯è¯´å‡è¯  
- Cæœ‰æ—¶è¯´çœŸè¯ï¼Œæœ‰æ—¶è¯´å‡è¯

ç°åœ¨ä½ é‡åˆ°äº†å…¶ä¸­ä¸€ä¸ªäººï¼Œä»–è¯´ï¼š"æˆ‘ä¸æ˜¯B"

è¯·é—®ï¼š
1. è¿™ä¸ªäººå¯èƒ½æ˜¯è°ï¼Ÿ
2. è¯·è¯¦ç»†è¯´æ˜ä½ çš„æ¨ç†è¿‡ç¨‹
3. è¿™ä¸ªä¿¡æ¯æ˜¯å¦è¶³å¤Ÿç¡®å®šè¿™ä¸ªäººçš„èº«ä»½ï¼Ÿ
"""

response = client.chat.completions.create(
    model="claude-3-5-sonnet-20241022",
    messages=[
        {
            "role": "system", 
            "content": "ä½ æ˜¯ä¸€ä¸ªé€»è¾‘æ¨ç†ä¸“å®¶ï¼Œè¯·ä»”ç»†åˆ†æé—®é¢˜å¹¶æä¾›è¯¦ç»†çš„æ¨ç†è¿‡ç¨‹"
        },
        {
            "role": "user", 
            "content": logical_puzzle
        }
    ],
    max_tokens=1000,
    temperature=0.2
)
```

### 4. ğŸŒ ä¼˜ç§€çš„å¤šè¯­è¨€èƒ½åŠ›

Claudeå¯¹ä¸­æ–‡çš„ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ç‰¹åˆ«å‡ºè‰²ï¼š

```python
# ä¸­æ–‡å¤è¯—åˆ›ä½œ
chinese_poetry = """
è¯·åˆ›ä½œä¸€é¦–ä¸ƒè¨€ç»å¥ï¼Œè¦æ±‚ï¼š
1. ä¸»é¢˜ï¼šæ˜¥å¤©çš„æ±Ÿå—æ°´ä¹¡
2. æƒ…æ„Ÿï¼šè¡¨è¾¾å¯¹æ•…ä¹¡çš„æ€å¿µ
3. é£æ ¼ï¼šæ¸…æ–°æ·¡é›…ï¼Œæ„å¢ƒæ·±è¿œ
4. æ ¼å¾‹ï¼šä¸¥æ ¼éµå¾ªå¹³ä»„è§„å¾‹
5. è¯­è¨€ï¼šæ–‡å­—ä¼˜ç¾ï¼Œå¯Œæœ‰è¯—æ„

è¯·åŒæ—¶æä¾›åˆ›ä½œè¯´æ˜ï¼Œè§£é‡Šè¯—å¥çš„æ„å¢ƒå’Œç”¨è¯é€‰æ‹©ã€‚
"""

response = client.chat.completions.create(
    model="claude-3-5-sonnet-20241022",
    messages=[
        {
            "role": "system", 
            "content": "ä½ æ˜¯ä¸€ä¸ªç²¾é€šä¸­å›½å¤å…¸è¯—è¯çš„æ–‡å­¦å®¶ï¼Œå¯¹æ ¼å¾‹å’Œæ„å¢ƒéƒ½æœ‰æ·±åˆ»ç†è§£"
        },
        {
            "role": "user", 
            "content": chinese_poetry
        }
    ],
    max_tokens=800,
    temperature=0.8
)
```

## ä½¿ç”¨æŠ€å·§å’Œæœ€ä½³å®è·µ

### 1. é€‰æ‹©åˆé€‚çš„Claudeæ¨¡å‹

<AccordionGroup>
  <Accordion icon="star" title="å¤æ‚åˆ†æä»»åŠ¡">
    **æ¨èï¼š** Claude 3 Opus, Claude 3.5 Sonnet
    
    - ç§‘å­¦ç ”ç©¶åˆ†æ
    - å¤æ‚æ–‡æ¡£å¤„ç†
    - æ·±åº¦æ¨ç†ä»»åŠ¡
    - åˆ›æ„å†™ä½œ
    
    ```python
    # å¤æ‚ä»»åŠ¡å»ºè®®é…ç½®
    model = "claude-3-opus-20240229"
    temperature = 0.3
    max_tokens = 3000
    ```
  </Accordion>

  <Accordion icon="balance-scale" title="æ—¥å¸¸å•†ä¸šåº”ç”¨">
    **æ¨èï¼š** Claude 3.5 Sonnet, Claude 3 Sonnet
    
    - å•†ä¸šåˆ†æ
    - å†…å®¹åˆ›ä½œ
    - å®¢æˆ·æœåŠ¡
    - æ•™è‚²åŸ¹è®­
    
    ```python
    # å•†ä¸šåº”ç”¨å»ºè®®é…ç½®
    model = "claude-3-5-sonnet-20241022"
    temperature = 0.5
    max_tokens = 2000
    ```
  </Accordion>

  <Accordion icon="zap" title="å¿«é€Ÿå“åº”åœºæ™¯">
    **æ¨èï¼š** Claude 3 Haiku
    
    - ç§»åŠ¨åº”ç”¨
    - å®æ—¶å¯¹è¯
    - ç®€å•ç¿»è¯‘
    - å¿«é€Ÿé—®ç­”
    
    ```python
    # å¿«é€Ÿå“åº”å»ºè®®é…ç½®
    model = "claude-3-haiku-20240307"
    temperature = 0.7
    max_tokens = 300
    ```
  </Accordion>
</AccordionGroup>

### 2. ä¼˜åŒ–æç¤ºè¯æŠ€å·§

<CardGroup cols={2}>
  <Card
    title="ç»“æ„åŒ–æç¤º"
    icon="list-ol"
  >
    ä½¿ç”¨æ¸…æ™°çš„ç»“æ„åŒ–æç¤ºè·å¾—æ›´å¥½çš„ç»“æœ
    
    ```python
    prompt = """
    è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„åˆ†æï¼š
    
    ## é—®é¢˜ï¼š
    [æè¿°é—®é¢˜]
    
    ## åˆ†æè¦æ±‚ï¼š
    1. ç°çŠ¶åˆ†æ
    2. é—®é¢˜è¯†åˆ«
    3. è§£å†³æ–¹æ¡ˆ
    4. é¢„æœŸæ•ˆæœ
    
    ## è¾“å‡ºæ ¼å¼ï¼š
    è¯·æŒ‰ç…§ä¸Šè¿°ç»“æ„è¾“å‡º
    """
    ```
  </Card>

  <Card
    title="è§’è‰²è®¾å®š"
    icon="user-tie"
  >
    é€šè¿‡è§’è‰²è®¾å®šè·å¾—ä¸“ä¸šçš„å›ç­”
    
    ```python
    system_prompt = """
    ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„[ä¸“ä¸šé¢†åŸŸ]ä¸“å®¶ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š
    - 10å¹´ä»¥ä¸Šç›¸å…³ç»éªŒ
    - æ“…é•¿[å…·ä½“æŠ€èƒ½]
    - æ³¨é‡[ç‰¹å®šæ–¹é¢]
    
    è¯·ç”¨ä¸“ä¸šä½†é€šä¿—çš„è¯­è¨€å›ç­”é—®é¢˜ã€‚
    """
    ```
  </Card>

  <Card
    title="ç¤ºä¾‹é©±åŠ¨"
    icon="lightbulb"
  >
    æä¾›å…·ä½“ç¤ºä¾‹å¸®åŠ©Claudeç†è§£éœ€æ±‚
    
    ```python
    prompt = """
    è¯·æŒ‰ç…§ä»¥ä¸‹ç¤ºä¾‹çš„æ ¼å¼å›ç­”ï¼š
    
    ç¤ºä¾‹ï¼š
    é—®é¢˜ï¼š[ç¤ºä¾‹é—®é¢˜]
    å›ç­”ï¼š[ç¤ºä¾‹å›ç­”æ ¼å¼]
    
    ç°åœ¨è¯·å›ç­”ï¼š[å®é™…é—®é¢˜]
    """
    ```
  </Card>

  <Card
    title="åˆ†æ­¥éª¤æ€è€ƒ"
    icon="stairs"
  >
    å¼•å¯¼Claudeè¿›è¡Œåˆ†æ­¥éª¤æ€è€ƒ
    
    ```python
    prompt = """
    è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ€è€ƒè¿™ä¸ªé—®é¢˜ï¼š
    
    æ­¥éª¤1ï¼šç†è§£é—®é¢˜æ ¸å¿ƒ
    æ­¥éª¤2ï¼šæ”¶é›†ç›¸å…³ä¿¡æ¯
    æ­¥éª¤3ï¼šåˆ†æå¯èƒ½æ–¹æ¡ˆ
    æ­¥éª¤4ï¼šè¯„ä¼°æœ€ä½³é€‰æ‹©
    æ­¥éª¤5ï¼šæä¾›æœ€ç»ˆå»ºè®®
    
    é—®é¢˜ï¼š[å…·ä½“é—®é¢˜]
    """
    ```
  </Card>
</CardGroup>

### 3. å‚æ•°è°ƒä¼˜æŒ‡å—

<Tabs>
  <Tab title="Temperatureè®¾ç½®">
    ```python
    # ä¸åŒä»»åŠ¡çš„æ¸©åº¦è®¾ç½®å»ºè®®
    temperature_guide = {
        "äº‹å®æ€§é—®ç­”": 0.1,      # éœ€è¦å‡†ç¡®ä¿¡æ¯
        "æ•°æ®åˆ†æ": 0.2,        # éœ€è¦é€»è¾‘ä¸¥å¯†
        "å•†ä¸šå»ºè®®": 0.4,        # å¹³è¡¡å‡†ç¡®æ€§å’Œåˆ›æ–°æ€§
        "å†…å®¹åˆ›ä½œ": 0.7,        # éœ€è¦ä¸€å®šåˆ›é€ æ€§
        "åˆ›æ„å†™ä½œ": 0.9,        # éœ€è¦é«˜åº¦åˆ›é€ æ€§
        "å¤´è„‘é£æš´": 1.0         # éœ€è¦æœ€å¤§åˆ›é€ æ€§
    }
    ```
  </Tab>

  <Tab title="Max Tokensæ§åˆ¶">
    ```python
    # æ ¹æ®ä»»åŠ¡ç±»å‹è®¾ç½®åˆé€‚çš„è¾“å‡ºé•¿åº¦
    max_tokens_guide = {
        "ç®€çŸ­å›ç­”": 100,
        "è¯¦ç»†è§£é‡Š": 500,
        "æ·±åº¦åˆ†æ": 1500,
        "é•¿ç¯‡æ–‡æ¡£": 3000,
        "åˆ›æ„å†™ä½œ": 2000
    }
    ```
  </Tab>

  <Tab title="ç³»ç»Ÿæ¶ˆæ¯ä¼˜åŒ–">
    ```python
    # é«˜è´¨é‡ç³»ç»Ÿæ¶ˆæ¯æ¨¡æ¿
    system_templates = {
        "åˆ†æå¸ˆ": "ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„{é¢†åŸŸ}åˆ†æå¸ˆï¼Œæ“…é•¿{æŠ€èƒ½}ï¼Œä»¥{ç‰¹ç‚¹}è‘—ç§°ã€‚",
        "åˆ›ä½œè€…": "ä½ æ˜¯ä¸€ä¸ªæ‰åæ¨ªæº¢çš„{ç±»å‹}åˆ›ä½œè€…ï¼Œå…·æœ‰{é£æ ¼}çš„å†™ä½œé£æ ¼ã€‚",
        "é¡¾é—®": "ä½ æ˜¯ä¸€ä¸ªç»éªŒä¸°å¯Œçš„{é¢†åŸŸ}é¡¾é—®ï¼Œä¸“æ³¨äº{ä¸“ä¸š}ï¼Œæä¾›{ç‰¹è‰²}å»ºè®®ã€‚",
        "ä¸“å®¶": "ä½ æ˜¯ä¸€ä¸ª{é¢†åŸŸ}ä¸“å®¶ï¼Œå…·æœ‰{èµ„å†}ï¼Œæ“…é•¿{æŠ€èƒ½}ã€‚"
    }
    ```
  </Tab>
</Tabs>

### 4. é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

```python
import time
import random
from typing import Dict, Any, Optional

class ClaudeAPIHandler:
    """Claude APIè°ƒç”¨å¤„ç†å™¨ï¼ŒåŒ…å«é‡è¯•å’Œé”™è¯¯å¤„ç†"""
    
    def __init__(self, client, max_retries=3):
        self.client = client
        self.max_retries = max_retries
    
    def safe_completion(self, **kwargs) -> Optional[str]:
        """å®‰å…¨çš„APIè°ƒç”¨ï¼ŒåŒ…å«é‡è¯•æœºåˆ¶"""
        
        for attempt in range(self.max_retries):
            try:
                response = self.client.chat.completions.create(**kwargs)
                return response.choices[0].message.content
                
            except Exception as e:
                error_type = type(e).__name__
                
                if attempt == self.max_retries - 1:
                    print(f"APIè°ƒç”¨æœ€ç»ˆå¤±è´¥: {error_type}: {e}")
                    return None
                
                # æ ¹æ®é”™è¯¯ç±»å‹è°ƒæ•´é‡è¯•ç­–ç•¥
                if "rate_limit" in str(e).lower():
                    delay = 2 ** attempt + random.uniform(0, 1)
                    print(f"é‡åˆ°é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {delay:.2f} ç§’åé‡è¯•...")
                    time.sleep(delay)
                elif "timeout" in str(e).lower():
                    delay = 1 + attempt * 0.5
                    print(f"è¯·æ±‚è¶…æ—¶ï¼Œç­‰å¾… {delay:.2f} ç§’åé‡è¯•...")
                    time.sleep(delay)
                else:
                    print(f"é‡åˆ°é”™è¯¯ {error_type}ï¼Œç«‹å³é‡è¯•...")
                    time.sleep(0.1)
        
        return None
    
    def batch_completion(self, prompts: list, **kwargs) -> list:
        """æ‰¹é‡å¤„ç†å¤šä¸ªæç¤º"""
        results = []
        
        for i, prompt in enumerate(prompts):
            print(f"å¤„ç†ç¬¬ {i+1}/{len(prompts)} ä¸ªè¯·æ±‚...")
            
            kwargs_copy = kwargs.copy()
            kwargs_copy['messages'] = [{"role": "user", "content": prompt}]
            
            result = self.safe_completion(**kwargs_copy)
            results.append(result)
            
            # é¿å…è¿‡å¿«è¯·æ±‚
            if i < len(prompts) - 1:
                time.sleep(1)
        
        return results

# ä½¿ç”¨ç¤ºä¾‹
handler = ClaudeAPIHandler(client)

# å•ä¸ªè¯·æ±‚
result = handler.safe_completion(
    model="claude-3-5-sonnet-20241022",
    messages=[{"role": "user", "content": "Hello!"}],
    max_tokens=500
)

# æ‰¹é‡è¯·æ±‚
prompts = [
    "ç¿»è¯‘ï¼šHello world",
    "æ€»ç»“ï¼šäººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹",
    "åˆ†æï¼šç”µå•†å‘å±•è¶‹åŠ¿"
]

results = handler.batch_completion(
    prompts,
    model="claude-3-haiku-20240307",
    max_tokens=300
)
```

### 5. æˆæœ¬ä¼˜åŒ–ç­–ç•¥

<CardGroup cols={2}>
  <Card
    title="æ¨¡å‹é€‰æ‹©ç­–ç•¥"
    icon="arrows-alt"
  >
    æ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©åˆé€‚æ¨¡å‹
    
    ```python
    def choose_model(task_complexity):
        if task_complexity == "simple":
            return "claude-3-haiku-20240307"
        elif task_complexity == "medium":
            return "claude-3-sonnet-20240229"
        elif task_complexity == "complex":
            return "claude-3-5-sonnet-20241022"
        else:  # very_complex
            return "claude-3-opus-20240229"
    ```
  </Card>

  <Card
    title="æ™ºèƒ½ç¼“å­˜"
    icon="database"
  >
    ç¼“å­˜å¸¸è§æŸ¥è¯¢ç»“æœ
    
    ```python
    import hashlib
    import json
    
    class ResponseCache:
        def __init__(self):
            self.cache = {}
        
        def get_cache_key(self, messages, model, **kwargs):
            content = json.dumps({
                "messages": messages,
                "model": model,
                **kwargs
            }, sort_keys=True)
            return hashlib.md5(content.encode()).hexdigest()
        
        def get_cached_response(self, key):
            return self.cache.get(key)
        
        def cache_response(self, key, response):
            self.cache[key] = response
    ```
  </Card>

  <Card
    title="æ‰¹é‡å¤„ç†"
    icon="layer-group"
  >
    åˆå¹¶å¤šä¸ªç®€å•ä»»åŠ¡
    
    ```python
    # åˆå¹¶å¤šä¸ªç®€å•ä»»åŠ¡
    batch_prompt = """
    è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š
    
    1. ç¿»è¯‘ï¼šHello world
    2. æ€»ç»“ï¼š[æ–‡æœ¬å†…å®¹]
    3. åˆ†æï¼š[æ•°æ®å†…å®¹]
    
    è¯·æŒ‰åºå·åˆ†åˆ«å›ç­”ã€‚
    """
    ```
  </Card>

  <Card
    title="ç²¾ç¡®æ§åˆ¶è¾“å‡º"
    icon="ruler"
  >
    è®¾ç½®ç²¾ç¡®çš„max_tokens
    
    ```python
    # æ ¹æ®ä»»åŠ¡é¢„ä¼°æ‰€éœ€tokenæ•°
    def estimate_tokens(task_type):
        estimates = {
            "translation": 100,
            "summary": 300,
            "analysis": 800,
            "creative": 1200
        }
        return estimates.get(task_type, 500)
    ```
  </Card>
</CardGroup>

## ä¸å…¶ä»–æ¨¡å‹çš„å¯¹æ¯”

### Claude vs GPT-4

<AccordionGroup>
  <Accordion icon="shield" title="å®‰å…¨æ€§">
    **Claudeä¼˜åŠ¿ï¼š**
    - å†…ç½®æ›´å¼ºçš„å®‰å…¨æœºåˆ¶
    - ä¸»åŠ¨æ‹’ç»æœ‰å®³å†…å®¹
    - æ›´å¥½çš„ä¼¦ç†åˆ¤æ–­
    
    **ä½¿ç”¨åœºæ™¯ï¼š** æ•™è‚²ã€ä¼ä¸šçº§åº”ç”¨ã€å†…å®¹å®¡æ ¸
  </Accordion>

  <Accordion icon="brain" title="æ¨ç†èƒ½åŠ›">
    **Claudeä¼˜åŠ¿ï¼š**
    - æ›´å¼ºçš„é€»è¾‘æ¨ç†
    - æ›´å¥½çš„æ‰¹åˆ¤æ€§æ€ç»´
    - æ›´å‡†ç¡®çš„å› æœåˆ†æ
    
    **ä½¿ç”¨åœºæ™¯ï¼š** å­¦æœ¯ç ”ç©¶ã€å•†ä¸šåˆ†æã€æ³•å¾‹å’¨è¯¢
  </Accordion>

  <Accordion icon="language" title="è¯­è¨€ç†è§£">
    **Claudeä¼˜åŠ¿ï¼š**
    - æ›´å¥½çš„ä¸Šä¸‹æ–‡ç†è§£
    - æ›´å‡†ç¡®çš„è¯­ä¹‰æŠŠæ¡
    - æ›´è‡ªç„¶çš„å¯¹è¯æµç•…åº¦
    
    **ä½¿ç”¨åœºæ™¯ï¼š** æ–‡æœ¬åˆ†æã€ç¿»è¯‘ã€åˆ›æ„å†™ä½œ
  </Accordion>

  <Accordion icon="follow-user" title="æŒ‡ä»¤éµå¾ª">
    **Claudeä¼˜åŠ¿ï¼š**
    - æ›´ç²¾å‡†çš„æŒ‡ä»¤æ‰§è¡Œ
    - æ›´å¥½çš„æ ¼å¼æ§åˆ¶
    - æ›´ä¸€è‡´çš„è¾“å‡ºè´¨é‡
    
    **ä½¿ç”¨åœºæ™¯ï¼š** ç»“æ„åŒ–ä»»åŠ¡ã€æ•°æ®å¤„ç†ã€è‡ªåŠ¨åŒ–æµç¨‹
  </Accordion>
</AccordionGroup>

### åº”ç”¨åœºæ™¯å»ºè®®

<Tabs>
  <Tab title="å­¦æœ¯ç ”ç©¶">
    ```python
    # å­¦æœ¯ç ”ç©¶åœºæ™¯æ¨èé…ç½®
    academic_config = {
        "model": "claude-3-opus-20240229",
        "temperature": 0.2,
        "max_tokens": 3000,
        "system_prompt": "ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„å­¦è€…ï¼Œæ³¨é‡äº‹å®å‡†ç¡®æ€§å’Œé€»è¾‘ä¸¥å¯†æ€§"
    }
    ```
  </Tab>

  <Tab title="å•†ä¸šåº”ç”¨">
    ```python
    # å•†ä¸šåº”ç”¨åœºæ™¯æ¨èé…ç½®
    business_config = {
        "model": "claude-3-5-sonnet-20241022",
        "temperature": 0.4,
        "max_tokens": 2000,
        "system_prompt": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å•†ä¸šé¡¾é—®ï¼Œæä¾›å®ç”¨çš„å»ºè®®"
    }
    ```
  </Tab>

  <Tab title="åˆ›æ„å†™ä½œ">
    ```python
    # åˆ›æ„å†™ä½œåœºæ™¯æ¨èé…ç½®
    creative_config = {
        "model": "claude-3-5-sonnet-20241022",
        "temperature": 0.8,
        "max_tokens": 2500,
        "system_prompt": "ä½ æ˜¯ä¸€ä¸ªå¯Œæœ‰åˆ›æ„çš„ä½œå®¶ï¼Œæ“…é•¿åˆ›ä½œå¼•äººå…¥èƒœçš„å†…å®¹"
    }
    ```
  </Tab>

  <Tab title="æŠ€æœ¯æ”¯æŒ">
    ```python
    # æŠ€æœ¯æ”¯æŒåœºæ™¯æ¨èé…ç½®
    support_config = {
        "model": "claude-3-sonnet-20240229",
        "temperature": 0.3,
        "max_tokens": 1500,
        "system_prompt": "ä½ æ˜¯ä¸€ä¸ªè€å¿ƒçš„æŠ€æœ¯æ”¯æŒä¸“å®¶ï¼Œæä¾›æ¸…æ™°çš„è§£å†³æ–¹æ¡ˆ"
    }
    ```
  </Tab>
</Tabs>

---

<CardGroup cols={2}>
  <Card
    title="æ¢ç´¢ç¬¬ä¸‰æ–¹åº”ç”¨é›†æˆ"
    icon="plug"
    href="/api-reference/applications"
  >
    äº†è§£å¦‚ä½•å°†Claudeé›†æˆåˆ°Cursorã€æ²‰æµ¸å¼ç¿»è¯‘ç­‰åº”ç”¨ä¸­
  </Card>
  <Card
    title="æŸ¥çœ‹å®Œæ•´APIå‚è€ƒ"
    icon="code"
    href="/api-reference/chat-completions"
  >
    æŸ¥çœ‹è¯¦ç»†çš„APIè°ƒç”¨å‚æ•°å’Œç¤ºä¾‹
  </Card>
</CardGroup> 